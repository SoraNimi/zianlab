D:\anaconda\envs\anyushi\python.exe D:/anyushi/deeplearning/zian/untitled1/ttest2.py
2022-01-10 13:58:24.832848: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
60000 train samples
10000 test samples
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
drop0 (DropoutNoScale)       (None, 784)               0
_________________________________________________________________
dense1 (BinaryDense1)        (None, 512)               401920
_________________________________________________________________
act1 (Activation)            (None, 512)               0
_________________________________________________________________
drop1 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense2 (BinaryDense2)        (None, 512)               262656
_________________________________________________________________
act2 (Activation)            (None, 512)               0
_________________________________________________________________
drop2 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense3 (BinaryDense3)        (None, 512)               262656
_________________________________________________________________
act3 (Activation)            (None, 512)               0
_________________________________________________________________
drop3 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense (BinaryDense)          (None, 10)                5130
=================================================================
Total params: 932,362
Trainable params: 930,816
Non-trainable params: 1,546
_________________________________________________________________
Epoch 1/200
469/469 [==============================] - 8s 17ms/step - loss: 1.2276 - acc: 0.8066 - val_loss: 0.6301 - val_acc: 0.9296
Epoch 2/200
469/469 [==============================] - 8s 17ms/step - loss: 0.7003 - acc: 0.8621 - val_loss: 0.6274 - val_acc: 0.9290
Epoch 3/200
469/469 [==============================] - 8s 16ms/step - loss: 0.6573 - acc: 0.8643 - val_loss: 0.5211 - val_acc: 0.9327
Epoch 4/200
469/469 [==============================] - 8s 16ms/step - loss: 0.6746 - acc: 0.8665 - val_loss: 0.5557 - val_acc: 0.9326
Epoch 5/200
469/469 [==============================] - 8s 16ms/step - loss: 0.6709 - acc: 0.8726 - val_loss: 0.5670 - val_acc: 0.9305
Epoch 6/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7104 - acc: 0.8699 - val_loss: 0.7160 - val_acc: 0.9279
Epoch 7/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7410 - acc: 0.8724 - val_loss: 0.7620 - val_acc: 0.9282
Epoch 8/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7831 - acc: 0.8730 - val_loss: 0.8780 - val_acc: 0.9295
Epoch 9/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7980 - acc: 0.8736 - val_loss: 0.8482 - val_acc: 0.9246
Epoch 10/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8212 - acc: 0.8734 - val_loss: 0.7903 - val_acc: 0.9272
Epoch 11/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8468 - acc: 0.8750 - val_loss: 1.0867 - val_acc: 0.9219
Epoch 12/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8900 - acc: 0.8741 - val_loss: 0.8039 - val_acc: 0.9271
Epoch 13/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8414 - acc: 0.8779 - val_loss: 0.8559 - val_acc: 0.9331
Epoch 14/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8968 - acc: 0.8758 - val_loss: 1.0290 - val_acc: 0.9270
Epoch 15/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9290 - acc: 0.8775 - val_loss: 1.0698 - val_acc: 0.9322
Epoch 16/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9148 - acc: 0.8789 - val_loss: 0.8838 - val_acc: 0.9279
Epoch 17/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9117 - acc: 0.8776 - val_loss: 1.0511 - val_acc: 0.9230
Epoch 18/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9248 - acc: 0.8763 - val_loss: 1.0193 - val_acc: 0.9235
Epoch 19/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9563 - acc: 0.8761 - val_loss: 0.9185 - val_acc: 0.9259
Epoch 20/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9399 - acc: 0.8788 - val_loss: 0.9661 - val_acc: 0.9289
Epoch 21/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9277 - acc: 0.8803 - val_loss: 0.9847 - val_acc: 0.9276
Epoch 22/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8995 - acc: 0.8798 - val_loss: 1.0065 - val_acc: 0.9340
Epoch 23/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9175 - acc: 0.8795 - val_loss: 0.7278 - val_acc: 0.9363
Epoch 24/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9130 - acc: 0.8808 - val_loss: 0.8739 - val_acc: 0.9283
Epoch 25/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9333 - acc: 0.8816 - val_loss: 0.9750 - val_acc: 0.9263
Epoch 26/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9138 - acc: 0.8802 - val_loss: 0.9023 - val_acc: 0.9272
Epoch 27/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9005 - acc: 0.8820 - val_loss: 0.9147 - val_acc: 0.9278
Epoch 28/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9356 - acc: 0.8824 - val_loss: 0.9133 - val_acc: 0.9336
Epoch 29/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9065 - acc: 0.8820 - val_loss: 0.9039 - val_acc: 0.9359
Epoch 30/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8967 - acc: 0.8826 - val_loss: 1.0257 - val_acc: 0.9339
Epoch 31/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9041 - acc: 0.8825 - val_loss: 0.9999 - val_acc: 0.9341
Epoch 32/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9166 - acc: 0.8821 - val_loss: 1.1338 - val_acc: 0.9295
Epoch 33/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9187 - acc: 0.8827 - val_loss: 0.8841 - val_acc: 0.9359
Epoch 34/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9230 - acc: 0.8829 - val_loss: 0.8932 - val_acc: 0.9302
Epoch 35/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8867 - acc: 0.8863 - val_loss: 1.0258 - val_acc: 0.9226
Epoch 36/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8758 - acc: 0.8872 - val_loss: 0.9365 - val_acc: 0.9346
Epoch 37/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8791 - acc: 0.8881 - val_loss: 0.9096 - val_acc: 0.9275
Epoch 38/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9215 - acc: 0.8828 - val_loss: 0.8773 - val_acc: 0.9381
Epoch 39/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9402 - acc: 0.8836 - val_loss: 0.8353 - val_acc: 0.9384
Epoch 40/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8767 - acc: 0.8867 - val_loss: 0.7818 - val_acc: 0.9261
Epoch 41/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8946 - acc: 0.8848 - val_loss: 0.9307 - val_acc: 0.9360
Epoch 42/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8776 - acc: 0.8855 - val_loss: 0.7174 - val_acc: 0.9369
Epoch 43/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8876 - acc: 0.8864 - val_loss: 0.7056 - val_acc: 0.9382
Epoch 44/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8919 - acc: 0.8835 - val_loss: 1.0326 - val_acc: 0.9300
Epoch 45/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8552 - acc: 0.8879 - val_loss: 0.9504 - val_acc: 0.9290
Epoch 46/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9134 - acc: 0.8862 - val_loss: 0.7680 - val_acc: 0.9337
Epoch 47/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8660 - acc: 0.8867 - val_loss: 1.0030 - val_acc: 0.9193
Epoch 48/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8799 - acc: 0.8869 - val_loss: 0.8194 - val_acc: 0.9381
Epoch 49/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8874 - acc: 0.8879 - val_loss: 0.7150 - val_acc: 0.9392
Epoch 50/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8800 - acc: 0.8881 - val_loss: 1.0775 - val_acc: 0.9255
Epoch 51/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8895 - acc: 0.8860 - val_loss: 0.9200 - val_acc: 0.9350
Epoch 52/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8527 - acc: 0.8921 - val_loss: 0.8004 - val_acc: 0.9386
Epoch 53/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8603 - acc: 0.8890 - val_loss: 1.1210 - val_acc: 0.9261
Epoch 54/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8736 - acc: 0.8883 - val_loss: 1.0841 - val_acc: 0.9272
Epoch 55/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8628 - acc: 0.8886 - val_loss: 0.7684 - val_acc: 0.9389
Epoch 56/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8767 - acc: 0.8894 - val_loss: 0.7048 - val_acc: 0.9332
Epoch 57/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8438 - acc: 0.8910 - val_loss: 1.0207 - val_acc: 0.9360
Epoch 58/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8495 - acc: 0.8902 - val_loss: 0.9094 - val_acc: 0.9317
Epoch 59/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8692 - acc: 0.8885 - val_loss: 1.0559 - val_acc: 0.9219
Epoch 60/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8671 - acc: 0.8901 - val_loss: 0.8512 - val_acc: 0.9366
Epoch 61/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8520 - acc: 0.8892 - val_loss: 0.8926 - val_acc: 0.9282
Epoch 62/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8722 - acc: 0.8877 - val_loss: 0.9198 - val_acc: 0.9344
Epoch 63/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8481 - acc: 0.8898 - val_loss: 0.7548 - val_acc: 0.9389
Epoch 64/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8618 - acc: 0.8882 - val_loss: 1.2634 - val_acc: 0.9265
Epoch 65/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8516 - acc: 0.8910 - val_loss: 0.7115 - val_acc: 0.9365
Epoch 66/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8923 - acc: 0.8888 - val_loss: 0.9222 - val_acc: 0.9358
Epoch 67/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8608 - acc: 0.8892 - val_loss: 0.7899 - val_acc: 0.9409
Epoch 68/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8768 - acc: 0.8905 - val_loss: 0.9657 - val_acc: 0.9339
Epoch 69/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8286 - acc: 0.8928 - val_loss: 0.9289 - val_acc: 0.9402
Epoch 70/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8796 - acc: 0.8903 - val_loss: 0.8466 - val_acc: 0.9420
Epoch 71/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8647 - acc: 0.8912 - val_loss: 1.1336 - val_acc: 0.9281
Epoch 72/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8353 - acc: 0.8930 - val_loss: 1.1501 - val_acc: 0.9248
Epoch 73/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8758 - acc: 0.8904 - val_loss: 0.7924 - val_acc: 0.9417
Epoch 74/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8126 - acc: 0.8945 - val_loss: 0.8363 - val_acc: 0.9313
Epoch 75/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8654 - acc: 0.8924 - val_loss: 0.9545 - val_acc: 0.9292
Epoch 76/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8387 - acc: 0.8946 - val_loss: 0.8654 - val_acc: 0.9310
Epoch 77/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8287 - acc: 0.8934 - val_loss: 0.9105 - val_acc: 0.9353
Epoch 78/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8561 - acc: 0.8937 - val_loss: 0.8481 - val_acc: 0.9395
Epoch 79/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8234 - acc: 0.8946 - val_loss: 0.8634 - val_acc: 0.9349
Epoch 80/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8156 - acc: 0.8963 - val_loss: 0.8357 - val_acc: 0.9383
Epoch 81/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8178 - acc: 0.8963 - val_loss: 0.7811 - val_acc: 0.9415
Epoch 82/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8180 - acc: 0.8949 - val_loss: 0.7939 - val_acc: 0.9394
Epoch 83/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8389 - acc: 0.8957 - val_loss: 0.7691 - val_acc: 0.9417
Epoch 84/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8053 - acc: 0.8939 - val_loss: 1.0752 - val_acc: 0.9355
Epoch 85/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8165 - acc: 0.8941 - val_loss: 0.8643 - val_acc: 0.9356
Epoch 86/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8052 - acc: 0.8966 - val_loss: 0.9192 - val_acc: 0.9368
Epoch 87/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8402 - acc: 0.8927 - val_loss: 0.9460 - val_acc: 0.9410
Epoch 88/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8360 - acc: 0.8946 - val_loss: 1.2610 - val_acc: 0.9290
Epoch 89/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8300 - acc: 0.8957 - val_loss: 1.0469 - val_acc: 0.9272
Epoch 90/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8182 - acc: 0.8946 - val_loss: 0.9059 - val_acc: 0.9413
Epoch 91/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8198 - acc: 0.8953 - val_loss: 0.9240 - val_acc: 0.9353
Epoch 92/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7920 - acc: 0.8967 - val_loss: 0.9758 - val_acc: 0.9341
Epoch 93/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8032 - acc: 0.8974 - val_loss: 0.8111 - val_acc: 0.9228
Epoch 94/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8115 - acc: 0.8942 - val_loss: 0.8962 - val_acc: 0.9342
Epoch 95/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8116 - acc: 0.8951 - val_loss: 0.9377 - val_acc: 0.9383
Epoch 96/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7943 - acc: 0.8964 - val_loss: 0.8685 - val_acc: 0.9334
Epoch 97/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8163 - acc: 0.8965 - val_loss: 0.9542 - val_acc: 0.9335
Epoch 98/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8249 - acc: 0.8966 - val_loss: 0.9735 - val_acc: 0.9377
Epoch 99/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7874 - acc: 0.8975 - val_loss: 0.7520 - val_acc: 0.9455
Epoch 100/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8216 - acc: 0.8951 - val_loss: 0.7495 - val_acc: 0.9401
Epoch 101/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8403 - acc: 0.8951 - val_loss: 0.8292 - val_acc: 0.9358
Epoch 102/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7948 - acc: 0.8973 - val_loss: 1.0314 - val_acc: 0.9341
Epoch 103/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8200 - acc: 0.8967 - val_loss: 0.9544 - val_acc: 0.9380
Epoch 104/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8085 - acc: 0.8980 - val_loss: 0.7361 - val_acc: 0.9436
Epoch 105/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8017 - acc: 0.8987 - val_loss: 0.8662 - val_acc: 0.9383
Epoch 106/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7901 - acc: 0.8996 - val_loss: 0.6937 - val_acc: 0.9423
Epoch 107/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8003 - acc: 0.9000 - val_loss: 0.7386 - val_acc: 0.9443
Epoch 108/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7900 - acc: 0.8983 - val_loss: 0.8451 - val_acc: 0.9394
Epoch 109/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8126 - acc: 0.8971 - val_loss: 0.8902 - val_acc: 0.9451
Epoch 110/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7879 - acc: 0.8995 - val_loss: 0.6967 - val_acc: 0.9430
Epoch 111/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7887 - acc: 0.8980 - val_loss: 0.7599 - val_acc: 0.9394
Epoch 112/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7949 - acc: 0.8982 - val_loss: 0.9596 - val_acc: 0.9332
Epoch 113/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7970 - acc: 0.8981 - val_loss: 0.6762 - val_acc: 0.9424
Epoch 114/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8218 - acc: 0.8973 - val_loss: 0.7923 - val_acc: 0.9426
Epoch 115/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7794 - acc: 0.9016 - val_loss: 0.9531 - val_acc: 0.9382
Epoch 116/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7930 - acc: 0.8998 - val_loss: 0.9166 - val_acc: 0.9335
Epoch 117/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8004 - acc: 0.9011 - val_loss: 1.1946 - val_acc: 0.9339
Epoch 118/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7783 - acc: 0.9019 - val_loss: 1.1417 - val_acc: 0.9297
Epoch 119/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7682 - acc: 0.9025 - val_loss: 0.9337 - val_acc: 0.9346
Epoch 120/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8204 - acc: 0.8996 - val_loss: 0.9466 - val_acc: 0.9410
Epoch 121/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7963 - acc: 0.9016 - val_loss: 0.9751 - val_acc: 0.9405
Epoch 122/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7802 - acc: 0.9011 - val_loss: 0.7814 - val_acc: 0.9393
Epoch 123/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7884 - acc: 0.8985 - val_loss: 0.9449 - val_acc: 0.9343
Epoch 124/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7620 - acc: 0.9020 - val_loss: 0.8538 - val_acc: 0.9395
Epoch 125/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7581 - acc: 0.9024 - val_loss: 1.1741 - val_acc: 0.9346
Epoch 126/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7805 - acc: 0.9006 - val_loss: 0.7820 - val_acc: 0.9438
Epoch 127/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7718 - acc: 0.9011 - val_loss: 0.9568 - val_acc: 0.9429
Epoch 128/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7717 - acc: 0.9017 - val_loss: 0.9830 - val_acc: 0.9423
Epoch 129/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7856 - acc: 0.9005 - val_loss: 0.8698 - val_acc: 0.9322
Epoch 130/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7989 - acc: 0.8996 - val_loss: 0.8493 - val_acc: 0.9363
Epoch 131/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7823 - acc: 0.9018 - val_loss: 1.1790 - val_acc: 0.9203
Epoch 132/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7434 - acc: 0.9022 - val_loss: 0.9668 - val_acc: 0.9336
Epoch 133/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7640 - acc: 0.9008 - val_loss: 0.7622 - val_acc: 0.9433
Epoch 134/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7646 - acc: 0.9025 - val_loss: 0.8188 - val_acc: 0.9430
Epoch 135/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7837 - acc: 0.9032 - val_loss: 0.7742 - val_acc: 0.9444
Epoch 136/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7707 - acc: 0.9025 - val_loss: 0.8172 - val_acc: 0.9437
Epoch 137/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7589 - acc: 0.9027 - val_loss: 0.9318 - val_acc: 0.9420
Epoch 138/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7396 - acc: 0.9043 - val_loss: 1.0829 - val_acc: 0.9254
Epoch 139/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8121 - acc: 0.8993 - val_loss: 0.7550 - val_acc: 0.9476
Epoch 140/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7664 - acc: 0.9016 - val_loss: 0.9083 - val_acc: 0.9417
Epoch 141/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7602 - acc: 0.9032 - val_loss: 0.7138 - val_acc: 0.9462
Epoch 142/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7359 - acc: 0.9043 - val_loss: 0.6832 - val_acc: 0.9466
Epoch 143/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7552 - acc: 0.9022 - val_loss: 0.7884 - val_acc: 0.9405
Epoch 144/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7490 - acc: 0.9045 - val_loss: 1.0256 - val_acc: 0.9341
Epoch 145/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7662 - acc: 0.9029 - val_loss: 0.8435 - val_acc: 0.9427
Epoch 146/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7671 - acc: 0.9042 - val_loss: 0.5870 - val_acc: 0.9473
Epoch 147/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7446 - acc: 0.9043 - val_loss: 1.0008 - val_acc: 0.9399
Epoch 148/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7970 - acc: 0.9013 - val_loss: 0.9795 - val_acc: 0.9330
Epoch 149/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7593 - acc: 0.9041 - val_loss: 1.1082 - val_acc: 0.9356
Epoch 150/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7644 - acc: 0.9031 - val_loss: 0.7539 - val_acc: 0.9447
Epoch 151/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7414 - acc: 0.9049 - val_loss: 0.7269 - val_acc: 0.9437
Epoch 152/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7720 - acc: 0.9038 - val_loss: 0.7388 - val_acc: 0.9420
Epoch 153/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7358 - acc: 0.9031 - val_loss: 0.8421 - val_acc: 0.9410
Epoch 154/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7398 - acc: 0.9052 - val_loss: 1.1311 - val_acc: 0.9365
Epoch 155/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7720 - acc: 0.9054 - val_loss: 0.8889 - val_acc: 0.9449
Epoch 156/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7211 - acc: 0.9048 - val_loss: 0.8331 - val_acc: 0.9317
Epoch 157/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7533 - acc: 0.9046 - val_loss: 0.8496 - val_acc: 0.9361
Epoch 158/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7055 - acc: 0.9062 - val_loss: 0.8832 - val_acc: 0.9426
Epoch 159/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7443 - acc: 0.9052 - val_loss: 0.8453 - val_acc: 0.9430
Epoch 160/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7415 - acc: 0.9051 - val_loss: 0.6251 - val_acc: 0.9471
Epoch 161/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7391 - acc: 0.9049 - val_loss: 0.9400 - val_acc: 0.9327
Epoch 162/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7474 - acc: 0.9076 - val_loss: 0.7069 - val_acc: 0.9500
Epoch 163/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7395 - acc: 0.9082 - val_loss: 0.6233 - val_acc: 0.9471
Epoch 164/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7265 - acc: 0.9081 - val_loss: 0.8640 - val_acc: 0.9420
Epoch 165/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7433 - acc: 0.9077 - val_loss: 0.7962 - val_acc: 0.9471
Epoch 166/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7256 - acc: 0.9082 - val_loss: 0.7348 - val_acc: 0.9434
Epoch 167/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7339 - acc: 0.9089 - val_loss: 0.9804 - val_acc: 0.9449
Epoch 168/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7471 - acc: 0.9084 - val_loss: 0.8234 - val_acc: 0.9469
Epoch 169/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7330 - acc: 0.9076 - val_loss: 0.7109 - val_acc: 0.9467
Epoch 170/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7410 - acc: 0.9065 - val_loss: 0.7610 - val_acc: 0.9451
Epoch 171/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7322 - acc: 0.9057 - val_loss: 0.8880 - val_acc: 0.9411
Epoch 172/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7532 - acc: 0.9057 - val_loss: 0.9297 - val_acc: 0.9436
Epoch 173/200
469/469 [==============================] - 7s 16ms/step - loss: 0.6979 - acc: 0.9086 - val_loss: 0.7084 - val_acc: 0.9444
Epoch 174/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7461 - acc: 0.9064 - val_loss: 0.9203 - val_acc: 0.9418
Epoch 175/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7168 - acc: 0.9091 - val_loss: 0.7070 - val_acc: 0.9500
Epoch 176/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7213 - acc: 0.9054 - val_loss: 0.7485 - val_acc: 0.9397
Epoch 177/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7593 - acc: 0.9065 - val_loss: 0.7325 - val_acc: 0.9469
Epoch 178/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7458 - acc: 0.9076 - val_loss: 0.7932 - val_acc: 0.9474
Epoch 179/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7264 - acc: 0.9071 - val_loss: 1.1149 - val_acc: 0.9321
Epoch 180/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7402 - acc: 0.9067 - val_loss: 0.9234 - val_acc: 0.9389
Epoch 181/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7147 - acc: 0.9100 - val_loss: 0.8134 - val_acc: 0.9458
Epoch 182/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7309 - acc: 0.9084 - val_loss: 0.8920 - val_acc: 0.9436
Epoch 183/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7208 - acc: 0.9088 - val_loss: 0.9142 - val_acc: 0.9425
Epoch 184/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7216 - acc: 0.9072 - val_loss: 0.7889 - val_acc: 0.9442
Epoch 185/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7008 - acc: 0.9078 - val_loss: 0.6662 - val_acc: 0.9403
Epoch 186/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7406 - acc: 0.9065 - val_loss: 0.7344 - val_acc: 0.9452
Epoch 187/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7100 - acc: 0.9069 - val_loss: 0.6858 - val_acc: 0.9455
Epoch 188/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7171 - acc: 0.9095 - val_loss: 0.6537 - val_acc: 0.9504
Epoch 189/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7226 - acc: 0.9102 - val_loss: 0.9042 - val_acc: 0.9358
Epoch 190/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7273 - acc: 0.9090 - val_loss: 0.7161 - val_acc: 0.9464
Epoch 191/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7002 - acc: 0.9097 - val_loss: 0.8294 - val_acc: 0.9437
Epoch 192/200
469/469 [==============================] - 7s 16ms/step - loss: 0.6958 - acc: 0.9099 - val_loss: 0.7238 - val_acc: 0.9451
Epoch 193/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7281 - acc: 0.9067 - val_loss: 0.7992 - val_acc: 0.9481
Epoch 194/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7345 - acc: 0.9092 - val_loss: 0.8558 - val_acc: 0.9390
Epoch 195/200
469/469 [==============================] - 7s 16ms/step - loss: 0.6927 - acc: 0.9089 - val_loss: 1.0212 - val_acc: 0.9362
Epoch 196/200
469/469 [==============================] - 7s 16ms/step - loss: 0.6871 - acc: 0.9107 - val_loss: 0.8192 - val_acc: 0.9478
Epoch 197/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7246 - acc: 0.9088 - val_loss: 0.8301 - val_acc: 0.9443
Epoch 198/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7215 - acc: 0.9106 - val_loss: 0.7022 - val_acc: 0.9466
Epoch 199/200
469/469 [==============================] - 7s 16ms/step - loss: 0.6979 - acc: 0.9119 - val_loss: 0.8768 - val_acc: 0.9460
Epoch 200/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7232 - acc: 0.9104 - val_loss: 0.7071 - val_acc: 0.9478
Test score: 0.7070600390434265
Test accuracy: 0.9477999806404114
D:\anaconda\envs\anyushi\lib\site-packages\numpy\lib\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr = np.asanyarray(arr)
0
[[ 16.  -19.  -18.5 -20.  -17.5 -16.  -19.5  -4.5 -11.  -16. ]]
0
[[ 15.5 -18.5 -18.  -17.5 -18.  -15.5 -23.   -9.  -15.5 -13.5]]
0
[[ 17.5 -18.5 -19.  -21.5 -22.  -14.5 -21.   -5.  -17.5 -13.5]]
0
[[ 17.5 -22.5 -18.  -18.5 -20.  -15.5 -25.   -5.  -13.5 -10.5]]
0
[[ 16.  -18.  -18.5 -20.  -20.5 -13.  -22.5  -6.5 -18.  -14. ]]
0
[[ 11.5 -18.5 -25.  -22.5 -21.  -14.5 -17.  -11.  -12.5 -11.5]]
0
[[ 17.5 -17.5 -21.  -21.5 -18.  -11.5 -22.   -8.  -15.5 -16.5]]
0
[[ 17.  -17.  -19.5 -22.  -17.5 -17.  -22.5  -6.5 -16.  -13. ]]
0
[[ 17.  -18.  -19.5 -23.  -20.5 -16.  -20.5  -6.5 -16.  -14. ]]
0
[[  7.  -18.   -9.5  -8.  -16.5  -8.  -19.5  -9.5 -15.  -11. ]]
0
[[ 15.5 -18.5 -18.  -19.5 -21.  -14.5 -23.   -7.  -17.5 -11.5]]
0
[[ 18.5 -16.5 -18.  -19.5 -20.  -12.5 -23.   -8.  -16.5 -12.5]]
0
[[ 16.5 -17.5 -18.  -19.5 -20.  -13.5 -22.   -7.  -15.5 -13.5]]
0
[[ 17.  -18.  -19.5 -20.  -19.5 -15.  -22.5  -8.5 -15.  -12. ]]
0
[[ 17.5 -18.5 -19.  -21.5 -19.  -15.5 -23.   -8.  -17.5 -13.5]]
0
[[ 16.  -19.  -20.5 -21.  -18.5 -17.  -21.5  -8.5 -18.  -13. ]]
0
[[ 16.  -18.  -20.5 -22.  -21.5 -15.  -20.5  -7.5 -17.  -14. ]]
0
[[ 16.  -16.  -13.5 -16.  -18.5 -16.  -23.5  -8.5 -13.  -10. ]]
0
[[ 18.  -20.  -17.5 -21.  -20.5 -13.  -22.5  -6.5 -15.  -12. ]]
0
[[ 16.  -17.  -19.5 -18.  -19.5 -12.  -21.5  -8.5 -16.  -12. ]]
1
[[-18.   17.  -19.5  -6.  -12.5 -13.   -8.5  -8.5 -17.  -13. ]]
1
[[-19.   19.  -17.5  -9.  -15.5 -13.   -6.5  -6.5 -18.  -13. ]]
1
[[-19.   19.  -17.5  -9.  -13.5 -12.   -9.5  -7.5 -17.  -14. ]]
1
[[-17.5  21.5 -20.  -14.5 -12.  -17.5  -7.   -8.  -17.5 -13.5]]
1
[[-18.   21.  -22.5 -12.  -12.5 -13.   -5.5  -7.5 -20.  -15. ]]
1
[[-20.5  18.5 -18.  -11.5 -13.  -16.5  -9.   -7.  -15.5 -12.5]]
1
[[-20.5  18.5 -22.   -9.5 -14.  -18.5  -9.   -4.  -16.5 -12.5]]
1
[[-21.5  19.5 -17.   -8.5 -13.  -14.5  -9.   -6.  -16.5 -15.5]]
1
[[-21.   17.  -17.5 -11.  -14.5 -15.   -8.5  -2.5 -16.  -12. ]]
1
[[-20.5  18.5 -19.  -11.5 -15.  -14.5  -7.   -5.  -16.5 -12.5]]
1
[[-17.5  18.5 -22.  -10.5 -13.  -15.5  -7.   -6.  -19.5 -14.5]]
1
[[-20.5  17.5 -18.  -11.5 -14.  -16.5  -9.   -4.  -16.5 -13.5]]
1
[[-21.   15.  -18.5  -9.  -14.5 -13.   -7.5  -4.5 -17.  -13. ]]
1
[[-20.5  16.5 -18.  -10.5 -15.  -14.5  -8.   -6.  -15.5 -13.5]]
1
[[-16.   20.  -18.5 -11.  -13.5 -14.  -10.5  -8.5 -14.  -17. ]]
1
[[-19.5  19.5 -22.   -7.5 -16.  -13.5  -8.   -8.  -14.5 -13.5]]
1
[[-21.5  18.5 -19.  -11.5 -14.  -15.5  -8.   -5.  -17.5 -12.5]]
1
[[-17.   20.  -20.5 -11.  -12.5 -13.  -10.5 -10.5 -15.  -17. ]]
1
[[-20.   17.  -17.5 -10.  -13.5 -14.   -9.5  -3.5 -16.  -13. ]]
1
[[-17.5  16.5 -21.   -6.5 -12.  -13.5 -11.   -9.  -16.5 -15.5]]
2
[[-12.5 -18.5  -4.  -10.5 -17.  -14.5 -21.   12.   -5.5 -15.5]]
2
[[-12.  -16.    9.5  -9.  -12.5 -10.  -19.5 -10.5 -17.  -10. ]]
2
[[ -6.  -16.    5.5  -8.  -20.5 -12.  -19.5  -5.5  -9.  -10. ]]
2
[[-17.5 -12.5   7.  -12.5 -15.   -6.5 -20.  -11.  -19.5 -13.5]]
2
[[-14.5  -9.5   9.  -13.5 -19.   -9.5 -15.  -11.  -16.5  -9.5]]
2
[[-17.  -12.    8.5 -13.  -15.5 -11.  -20.5 -10.5 -22.  -13. ]]
2
[[ 11.5 -15.5 -12.  -15.5 -23.  -16.5 -22.   -8.  -16.5  -8.5]]
2
[[-16.5 -13.5   8.   -9.5 -19.   -9.5 -23.  -11.  -16.5 -13.5]]
2
[[-14.5 -10.5   8.  -11.5 -18.   -9.5 -18.  -11.  -17.5 -11.5]]
2
[[-12.  -10.    3.5 -12.  -24.5  -6.  -20.5 -10.5  -9.  -10. ]]
2
[[-16.5 -11.5   8.  -10.5 -12.  -12.5 -16.  -14.  -14.5 -13.5]]
2
[[-21.  -14.   10.5  -7.  -10.5  -8.  -21.5  -9.5 -18.  -16. ]]
2
[[-18.  -14.   14.5 -15.  -13.5 -10.  -16.5 -10.5 -20.  -15. ]]
2
[[-15.   -1.    6.5  -6.  -18.5  -7.  -16.5  -5.5 -11.  -12. ]]
2
[[-13.   -4.    2.5  -8.  -24.5  -9.  -22.5  -9.5  -6.   -9. ]]
2
[[-15.5 -12.5  10.  -13.5 -16.   -8.5 -20.  -13.  -20.5 -13.5]]
2
[[-15.  -12.   10.5 -12.  -14.5 -13.  -19.5  -9.5 -19.  -13. ]]
2
[[-15.  -15.    8.5 -10.   -8.5 -12.  -14.5 -11.5 -16.  -12. ]]
2
[[-13.5 -13.5  11.  -13.5 -12.  -12.5 -17.  -17.  -13.5 -12.5]]
2
[[-10.5 -21.5 -12.   -2.5 -12.   -9.5 -13.  -19.   -7.5 -14.5]]
3
[[-24.5 -11.5 -21.    7.5 -11.  -14.5 -20.  -13.  -10.5 -12.5]]
3
[[-21.  -14.  -23.5  10.  -13.5 -13.  -21.5 -16.5  -9.  -15. ]]
3
[[-21.5 -13.5 -24.   13.5 -14.  -16.5 -21.  -13.  -14.5 -19.5]]
3
[[-19.  -12.  -21.5  13.  -16.5  -9.  -23.5 -10.5 -11.  -19. ]]
3
[[-22.  -13.  -23.5   9.  -11.5 -15.  -21.5 -12.5 -13.  -20. ]]
3
[[-22.  -11.  -23.5   8.  -13.5 -15.  -18.5  -6.5  -9.  -18. ]]
3
[[-22.5 -13.5 -24.   14.5 -14.  -16.5 -21.  -12.  -15.5 -17.5]]
3
[[-20.  -16.  -20.5  11.  -14.5 -13.  -22.5 -13.5 -17.  -23. ]]
3
[[-19.5 -13.5 -19.   13.5 -14.  -10.5 -20.  -12.  -13.5 -21.5]]
3
[[-20.  -15.  -23.5   3.  -15.5  -6.  -20.5 -20.5   0.  -13. ]]
3
[[-19.5 -14.5 -23.   11.5 -14.  -12.5 -21.  -11.  -16.5 -21.5]]
3
[[-21.  -13.  -24.5  14.  -14.5 -16.  -20.5 -12.5 -15.  -18. ]]
3
[[-21.  -13.  -18.5   1.  -21.5   6.  -17.5 -19.5  -3.  -17. ]]
3
[[ -7.5 -12.5 -15.    1.5 -20.    4.5 -22.  -11.   -7.5 -14.5]]
3
[[-20.  -19.  -18.5  13.  -15.5 -10.  -20.5 -11.5 -12.  -21. ]]
3
[[-20.5 -15.5 -17.   13.5 -21.  -14.5 -23.   -9.   -8.5 -17.5]]
3
[[-18.  -15.  -20.5  15.  -13.5 -13.  -21.5 -13.5 -16.  -22. ]]
3
[[-12.  -17.  -12.5   3.  -18.5  -2.  -24.5  -7.5  -8.  -12. ]]
3
[[-24.5  -9.5 -27.   -0.5 -12.    2.5 -24.   -8.  -10.5 -12.5]]
3
[[-24.5 -10.5 -21.    5.5 -13.   -8.5 -21.   -9.   -8.5 -13.5]]
4
[[-24.  -18.  -16.5 -14.    5.5 -20.  -14.5 -11.5 -23.   -7. ]]
4
[[-22.  -19.  -18.5 -12.    8.5 -20.  -16.5 -14.5 -17.   -5. ]]
4
[[-20.5 -12.5 -11.   -8.5   1.  -21.5  -9.   -8.   -7.5  -6.5]]
4
[[-21.5 -17.5 -18.  -15.5   8.  -18.5 -16.  -14.  -22.5  -7.5]]
4
[[-24.  -20.  -15.5 -11.   11.5 -20.  -12.5  -6.5 -19.  -11. ]]
4
[[-20.  -18.  -15.5 -14.    9.5 -19.  -18.5 -14.5 -18.   -8. ]]
4
[[-19.5 -17.5 -16.  -12.5  10.  -18.5 -16.  -14.  -17.5  -6.5]]
4
[[-21.5 -19.5 -17.  -14.5  11.  -19.5 -16.  -12.  -17.5  -6.5]]
4
[[-18.  -19.  -12.5 -12.    5.5 -15.  -17.5 -13.5  -5.   -4. ]]
4
[[-22.  -20.  -17.5 -14.   10.5 -18.  -14.5 -15.5 -21.   -9. ]]
4
[[-23.  -20.  -17.5 -14.   10.5 -19.  -16.5 -12.5 -22.   -6. ]]
4
[[-25.5  -9.5 -23.   -6.5  -1.  -19.5 -15.  -12.  -12.5   1.5]]
4
[[-18.  -19.  -13.5 -14.    6.5 -14.  -11.5 -18.5 -15.   -8. ]]
4
[[-24.  -20.  -17.5 -12.   10.5 -18.  -13.5 -13.5 -20.   -7. ]]
4
[[-22.  -13.  -17.5 -11.    5.5 -18.  -17.5  -6.5 -16.  -11. ]]
4
[[-21.  -19.  -20.5 -13.    8.5 -19.  -13.5 -13.5 -17.   -7. ]]
4
[[-22.5 -18.5 -18.  -14.5  10.  -18.5 -16.  -12.  -21.5  -7.5]]
4
[[-22.  -19.  -16.5 -15.    9.5 -19.  -16.5 -15.5 -23.   -8. ]]
4
[[-26.5  -5.5 -14.   -1.5   3.  -22.5 -10.    0.  -11.5 -10.5]]
4
[[-24.  -20.  -19.5 -14.    7.5 -19.  -16.5  -9.5 -20.   -5. ]]
5
[[-19.  -11.  -21.5 -14.  -20.5   6.  -11.5 -21.5 -16.  -14. ]]
5
[[-19.5 -11.5 -25.  -13.5 -22.    8.5 -15.  -24.  -16.5 -16.5]]
5
[[-15.5  -9.5 -16.  -11.5 -11.   12.5 -15.  -12.  -14.5 -11.5]]
5
[[-16.   -6.  -14.5 -14.  -13.5   4.  -10.5 -10.5 -10.  -13. ]]
5
[[-18.5  -9.5 -24.  -17.5 -18.    8.5 -17.  -19.  -18.5 -18.5]]
5
[[-16.5  -6.5 -19.  -11.5 -14.    8.5 -14.  -11.  -14.5 -12.5]]
5
[[-19.5 -11.5 -14.  -12.5 -11.   14.5 -12.  -13.  -16.5  -9.5]]
5
[[-14.5  -5.5 -15.   -9.5 -10.   11.5 -15.  -11.  -13.5 -10.5]]
5
[[-18.5 -15.5 -21.  -12.5 -20.    8.5 -14.  -23.  -14.5 -13.5]]
5
[[-21.  -16.  -29.5 -15.  -18.5  12.  -15.5 -19.5 -14.  -17. ]]
5
[[-21.  -11.  -21.5 -13.  -12.5   6.  -12.5 -10.5 -15.  -13. ]]
5
[[-21.5  -9.5 -29.  -17.5 -18.   10.5 -18.  -16.  -17.5 -18.5]]
5
[[-21.5 -17.5 -26.  -15.5 -20.   10.5 -14.  -24.  -18.5 -13.5]]
5
[[-22.5 -13.5 -25.   -6.5  -3.   -6.5 -10.  -12.  -14.5  -6.5]]
5
[[-19.5 -13.5 -31.  -15.5 -20.    5.5 -14.  -16.  -16.5 -17.5]]
5
[[-18.5 -17.5 -29.  -16.5 -18.   11.5 -17.  -23.  -16.5 -15.5]]
5
[[-18.  -16.  -24.5 -15.  -18.5  11.  -14.5 -25.5 -17.  -13. ]]
5
[[-18.5 -11.5 -21.  -11.5 -23.   11.5 -14.  -24.  -17.5 -17.5]]
5
[[-20.5 -12.5 -26.  -12.5 -17.    8.5 -14.   -9.  -16.5 -14.5]]
5
[[-18.5  -8.5 -25.  -15.5 -11.    8.5 -16.  -14.  -19.5 -14.5]]
6
[[-17.5 -19.5 -18.   -5.5 -14.  -15.5  14.  -15.  -10.5 -14.5]]
6
[[-17.  -18.  -17.5  -8.  -17.5 -15.   15.5 -15.5 -12.  -11. ]]
6
[[-17.  -19.  -20.5  -4.  -13.5 -16.   12.5 -15.5 -11.  -13. ]]
6
[[-16.  -17.  -20.5  -7.  -12.5 -17.   12.5 -16.5 -13.  -13. ]]
6
[[-21.5 -18.5 -24.   -4.5 -13.  -15.5   9.  -21.  -11.5 -13.5]]
6
[[-19.5 -18.5 -18.  -10.5 -16.  -16.5  12.  -15.  -14.5 -14.5]]
6
[[-18.  -19.  -16.5  -9.  -15.5 -20.   12.5 -13.5 -17.  -14. ]]
6
[[-19.5 -18.5 -19.  -10.5 -16.  -18.5  14.  -15.  -16.5 -15.5]]
6
[[-18.  -20.  -20.5  -9.  -17.5 -16.   14.5 -15.5 -15.  -17. ]]
6
[[-18.5 -18.5 -20.   -7.5 -16.  -21.5  15.  -17.  -15.5 -18.5]]
6
[[-16.5 -20.5 -16.   -7.5 -15.  -18.5  14.  -13.  -16.5 -13.5]]
6
[[-16.  -20.  -18.5  -6.  -17.5 -16.   15.5 -15.5 -14.  -19. ]]
6
[[-20.  -20.  -19.5  -7.  -17.5 -20.   17.5 -17.5 -14.  -18. ]]
6
[[-19.5 -18.5 -19.   -7.5 -14.  -18.5  15.  -14.  -16.5 -15.5]]
6
[[-16.5 -18.5 -17.   -7.5 -13.  -19.5  13.  -13.  -17.5 -14.5]]
6
[[-18.  -19.  -20.5  -8.  -17.5 -19.   13.5 -19.5 -16.  -18. ]]
6
[[-17.5 -20.5 -18.   -7.5 -19.  -16.5  16.  -17.  -13.5 -16.5]]
6
[[-18.5 -20.5 -21.   -9.5 -20.  -15.5  12.  -20.  -15.5 -18.5]]
6
[[-18.  -22.  -14.5 -10.  -11.5 -18.   12.5 -11.5 -15.  -14. ]]
6
[[-18.5 -19.5 -20.   -8.5 -19.  -16.5  15.  -16.  -14.5 -17.5]]
7
[[-22.  -21.  -17.5 -15.  -14.5 -17.  -24.5  30.5 -14.  -14. ]]
7
[[-19.5 -17.5 -19.  -18.5 -16.  -18.5 -24.   29.  -14.5 -17.5]]
7
[[-23.5  -9.5 -18.  -10.5 -12.  -14.5 -22.   26.  -10.5 -11.5]]
7
[[-18.5 -20.5 -23.  -17.5 -19.  -16.5 -24.   27.  -11.5 -13.5]]
7
[[-22.  -19.  -19.5 -15.  -14.5 -14.  -25.5  28.5 -14.  -17. ]]
7
[[-21.  -19.  -16.5 -16.  -12.5 -15.  -23.5  28.5 -15.  -17. ]]
7
[[-17.5 -16.5 -18.  -17.5 -16.  -16.5 -25.   29.  -15.5 -18.5]]
7
[[-22.5 -18.5 -22.  -17.5 -13.  -16.5 -26.   28.  -15.5 -15.5]]
7
[[-23.  -20.  -19.5 -17.  -15.5 -14.  -23.5  27.5 -13.  -16. ]]
7
[[-24.  -20.  -19.5 -16.  -15.5 -14.  -25.5  28.5 -14.  -15. ]]
7
[[-15.  -21.  -17.5 -20.  -17.5 -17.  -26.5  24.5 -15.  -14. ]]
7
[[-24.5 -16.5 -21.  -14.5 -11.  -15.5 -26.   27.  -14.5 -15.5]]
7
[[-22.  -21.  -17.5 -15.  -12.5 -16.  -23.5  28.5 -15.  -15. ]]
7
[[-23.  -20.  -20.5 -16.  -14.5 -14.  -24.5  27.5 -13.  -17. ]]
7
[[-23.5 -19.5 -18.  -16.5 -15.  -14.5 -25.   27.  -13.5 -15.5]]
7
[[-21.  -19.  -19.5 -18.  -12.5 -16.  -26.5  29.5 -14.  -17. ]]
7
[[-21.  -19.  -17.5 -15.  -13.5 -17.  -23.5  27.5 -16.  -15. ]]
7
[[-19.5 -16.5 -19.  -17.5 -17.  -16.5 -24.   28.  -14.5 -18.5]]
7
[[-22.  -18.  -19.5 -16.  -18.5 -16.  -27.5  27.5 -15.  -15. ]]
7
[[-14.  -21.  -18.5 -17.  -15.5 -13.  -22.5  26.5 -14.  -14. ]]
8
[[-12.5 -13.5 -16.  -12.5 -24.  -12.5 -18.  -16.    8.5 -12.5]]
8
[[-10.   -7.  -13.5  -6.  -14.5 -13.  -17.5 -12.5  12.  -14. ]]
8
[[ -4.5 -13.5 -16.  -12.5 -21.  -13.5 -17.  -19.   10.5 -10.5]]
8
[[-10.  -12.  -17.5 -10.  -22.5 -13.  -17.5 -19.5  11.  -12. ]]
8
[[ -8.  -14.  -13.5 -12.  -21.5 -14.  -22.5 -15.5   9.   -9. ]]
8
[[-11.5 -12.5 -15.  -11.5 -24.   -9.5 -21.  -18.    8.5 -14.5]]
8
[[ -9.   -8.  -16.5  -6.  -18.5 -13.  -16.5 -20.5  10.  -13. ]]
8
[[ -8.  -11.  -19.5 -11.  -22.5 -12.  -21.5 -18.5  10.  -12. ]]
8
[[ -1.  -16.  -20.5 -10.  -18.5 -12.  -13.5 -19.5  13.   -7. ]]
8
[[ -7.  -10.  -20.5 -12.  -22.5 -16.  -18.5 -16.5  11.  -12. ]]
8
[[-10.5  -9.5 -13.   -8.5 -15.   -9.5 -18.  -23.   10.5 -13.5]]
8
[[ -7.5 -10.5 -14.   -4.5 -14.  -13.5 -18.  -22.    7.5  -7.5]]
8
[[ -9.  -10.  -17.5 -14.  -25.5 -14.  -16.5 -16.5  11.  -11. ]]
8
[[-11.   -9.  -15.5 -14.  -25.5 -13.  -18.5 -17.5  10.  -14. ]]
8
[[-10.5 -12.5 -19.   -9.5 -23.  -11.5 -15.  -18.   10.5 -11.5]]
8
[[-10.   -7.  -16.5 -12.  -11.5   0.   -6.5 -16.5  -3.   -6. ]]
8
[[-10.   -8.  -12.5 -15.  -25.5 -10.  -21.5 -16.5  14.  -14. ]]
8
[[-12.5 -10.5 -17.  -12.5 -23.   -8.5 -20.  -22.   11.5 -10.5]]
8
[[-14.   -9.  -19.5 -11.  -22.5 -10.  -13.5 -15.5   9.  -10. ]]
8
[[ -8.5 -11.5 -15.  -12.5 -22.  -13.5 -16.  -20.    9.5 -12.5]]
9
[[-18.  -24.  -25.5 -11.  -15.5 -20.  -13.5   2.5 -12.    2. ]]
9
[[-15.  -17.  -16.5 -15.    2.5 -17.  -14.5  -8.5 -12.   -5. ]]
9
[[-18.  -21.  -31.5 -16.  -17.5 -10.  -19.5   3.5 -14.   -1. ]]
9
[[-22.5 -12.5 -27.  -15.5 -11.  -15.5 -18.   -1.  -16.5   4.5]]
9
[[-26.5 -18.5 -27.  -10.5 -19.  -13.5 -17.  -15.  -16.5  12.5]]
9
[[-25.  -17.  -24.5 -13.  -20.5 -17.  -14.5 -12.5 -13.   10. ]]
9
[[-24.5 -18.5 -20.  -15.5 -15.  -14.5 -13.  -17.  -11.5   6.5]]
9
[[-28.5 -16.5 -27.  -12.5 -19.  -11.5 -14.  -12.  -13.5  10.5]]
9
[[-22.  -17.  -22.5 -12.  -19.5 -20.  -17.5 -14.5 -12.   11. ]]
9
[[-25.  -19.  -24.5 -14.  -20.5 -17.  -15.5 -13.5 -14.   11. ]]
9
[[-25.  -16.  -24.5 -15.  -20.5 -16.  -13.5 -14.5 -14.   10. ]]
9
[[-26.  -18.  -22.5 -14.  -22.5 -17.  -14.5 -12.5 -15.   10. ]]
9
[[-26.5  -8.5 -27.   -8.5 -17.  -10.5 -14.  -11.  -14.5   6.5]]
9
[[-19.5 -16.5 -22.  -13.5 -21.  -17.5 -15.  -14.  -12.5  12.5]]
9
[[-23.5 -17.5 -26.  -14.5 -19.  -12.5 -10.  -16.  -10.5   6.5]]
9
[[-25.  -19.  -25.5 -14.  -21.5 -14.  -13.5 -12.5 -12.    9. ]]
9
[[-24.5 -18.5 -24.  -15.5 -24.  -15.5 -13.  -12.  -10.5  10.5]]
9
[[-27.  -21.  -24.5 -14.  -18.5 -15.  -12.5 -14.5 -11.    9. ]]
9
[[-16.  -18.  -18.5 -14.  -10.5 -18.  -18.5   6.5 -12.    3. ]]
9
[[-21.5 -13.5 -25.  -13.5 -22.  -10.5 -15.  -10.  -10.5   9.5]]

进程已结束,退出代码0
