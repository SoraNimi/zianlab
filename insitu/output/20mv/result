D:\anaconda\envs\anyushi\python.exe D:/anyushi/deeplearning/zian/untitled1/ttest2.py
2022-01-10 10:49:09.759954: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
60000 train samples
10000 test samples
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
drop0 (DropoutNoScale)       (None, 784)               0
_________________________________________________________________
dense1 (BinaryDense1)        (None, 512)               401920
_________________________________________________________________
act1 (Activation)            (None, 512)               0
_________________________________________________________________
drop1 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense2 (BinaryDense2)        (None, 512)               262656
_________________________________________________________________
act2 (Activation)            (None, 512)               0
_________________________________________________________________
drop2 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense3 (BinaryDense3)        (None, 512)               262656
_________________________________________________________________
act3 (Activation)            (None, 512)               0
_________________________________________________________________
drop3 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense (BinaryDense)          (None, 10)                5130
=================================================================
Total params: 932,362
Trainable params: 930,816
Non-trainable params: 1,546
_________________________________________________________________
Epoch 1/200
469/469 [==============================] - 8s 17ms/step - loss: 2.0000 - acc: 0.7107 - val_loss: 0.9225 - val_acc: 0.8910
Epoch 2/200
469/469 [==============================] - 8s 17ms/step - loss: 0.9317 - acc: 0.7963 - val_loss: 0.8446 - val_acc: 0.8908
Epoch 3/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9157 - acc: 0.7983 - val_loss: 0.9162 - val_acc: 0.8875
Epoch 4/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9053 - acc: 0.8105 - val_loss: 0.8940 - val_acc: 0.8901
Epoch 5/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9197 - acc: 0.8142 - val_loss: 0.9027 - val_acc: 0.8979
Epoch 6/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9753 - acc: 0.8137 - val_loss: 0.9596 - val_acc: 0.8919
Epoch 7/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0274 - acc: 0.8131 - val_loss: 0.9943 - val_acc: 0.8974
Epoch 8/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0527 - acc: 0.8186 - val_loss: 1.2681 - val_acc: 0.8912
Epoch 9/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1411 - acc: 0.8171 - val_loss: 1.3517 - val_acc: 0.8900
Epoch 10/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1959 - acc: 0.8159 - val_loss: 1.4395 - val_acc: 0.8938
Epoch 11/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1571 - acc: 0.8234 - val_loss: 1.3300 - val_acc: 0.8939
Epoch 12/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2637 - acc: 0.8184 - val_loss: 1.5281 - val_acc: 0.8837
Epoch 13/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2752 - acc: 0.8207 - val_loss: 1.5092 - val_acc: 0.8938
Epoch 14/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2538 - acc: 0.8232 - val_loss: 1.5039 - val_acc: 0.8887
Epoch 15/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2497 - acc: 0.8261 - val_loss: 1.6406 - val_acc: 0.8943
Epoch 16/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3069 - acc: 0.8252 - val_loss: 1.5367 - val_acc: 0.8897
Epoch 17/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2555 - acc: 0.8289 - val_loss: 1.3832 - val_acc: 0.8920
Epoch 18/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2357 - acc: 0.8329 - val_loss: 1.3892 - val_acc: 0.8951
Epoch 19/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2050 - acc: 0.8326 - val_loss: 1.3257 - val_acc: 0.9031
Epoch 20/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2587 - acc: 0.8326 - val_loss: 1.4271 - val_acc: 0.9012
Epoch 21/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2570 - acc: 0.8311 - val_loss: 1.4083 - val_acc: 0.9052
Epoch 22/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2295 - acc: 0.8373 - val_loss: 1.3967 - val_acc: 0.9023
Epoch 23/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2110 - acc: 0.8396 - val_loss: 1.3002 - val_acc: 0.9022
Epoch 24/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2208 - acc: 0.8370 - val_loss: 1.4113 - val_acc: 0.8942
Epoch 25/200
469/469 [==============================] - 7s 16ms/step - loss: 1.2360 - acc: 0.8373 - val_loss: 1.2981 - val_acc: 0.9031
Epoch 26/200
469/469 [==============================] - 7s 16ms/step - loss: 1.2473 - acc: 0.8420 - val_loss: 1.3492 - val_acc: 0.9036
Epoch 27/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1800 - acc: 0.8440 - val_loss: 2.1450 - val_acc: 0.8843
Epoch 28/200
469/469 [==============================] - 7s 16ms/step - loss: 1.2035 - acc: 0.8442 - val_loss: 1.3064 - val_acc: 0.9075
Epoch 29/200
469/469 [==============================] - 7s 16ms/step - loss: 1.2163 - acc: 0.8464 - val_loss: 1.1868 - val_acc: 0.9099
Epoch 30/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1787 - acc: 0.8469 - val_loss: 1.1365 - val_acc: 0.9149
Epoch 31/200
469/469 [==============================] - 7s 16ms/step - loss: 1.2049 - acc: 0.8464 - val_loss: 1.3058 - val_acc: 0.8997
Epoch 32/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1308 - acc: 0.8501 - val_loss: 1.0962 - val_acc: 0.9103
Epoch 33/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1713 - acc: 0.8482 - val_loss: 1.3082 - val_acc: 0.9027
Epoch 34/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1821 - acc: 0.8477 - val_loss: 1.6751 - val_acc: 0.9011
Epoch 35/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1415 - acc: 0.8502 - val_loss: 1.3230 - val_acc: 0.9141
Epoch 36/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1461 - acc: 0.8525 - val_loss: 1.5185 - val_acc: 0.8966
Epoch 37/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1346 - acc: 0.8526 - val_loss: 1.3990 - val_acc: 0.9114
Epoch 38/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1526 - acc: 0.8511 - val_loss: 1.3737 - val_acc: 0.9070
Epoch 39/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1368 - acc: 0.8540 - val_loss: 1.2249 - val_acc: 0.9089
Epoch 40/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0949 - acc: 0.8548 - val_loss: 1.1500 - val_acc: 0.9193
Epoch 41/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1147 - acc: 0.8558 - val_loss: 1.8552 - val_acc: 0.8958
Epoch 42/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1446 - acc: 0.8562 - val_loss: 1.3812 - val_acc: 0.9090
Epoch 43/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1222 - acc: 0.8554 - val_loss: 1.2380 - val_acc: 0.9140
Epoch 44/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1681 - acc: 0.8542 - val_loss: 1.3554 - val_acc: 0.9155
Epoch 45/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0627 - acc: 0.8584 - val_loss: 1.2490 - val_acc: 0.9098
Epoch 46/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0951 - acc: 0.8596 - val_loss: 1.4897 - val_acc: 0.9040
Epoch 47/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1114 - acc: 0.8597 - val_loss: 1.2156 - val_acc: 0.9064
Epoch 48/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0861 - acc: 0.8601 - val_loss: 1.2456 - val_acc: 0.9137
Epoch 49/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0589 - acc: 0.8598 - val_loss: 1.1025 - val_acc: 0.9198
Epoch 50/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0760 - acc: 0.8607 - val_loss: 1.0868 - val_acc: 0.9151
Epoch 51/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1407 - acc: 0.8592 - val_loss: 1.1519 - val_acc: 0.9168
Epoch 52/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0373 - acc: 0.8641 - val_loss: 1.1243 - val_acc: 0.9161
Epoch 53/200
469/469 [==============================] - 7s 16ms/step - loss: 1.1109 - acc: 0.8605 - val_loss: 1.1565 - val_acc: 0.9182
Epoch 54/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0328 - acc: 0.8631 - val_loss: 0.9527 - val_acc: 0.9091
Epoch 55/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0539 - acc: 0.8635 - val_loss: 1.3517 - val_acc: 0.9141
Epoch 56/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0580 - acc: 0.8636 - val_loss: 1.3936 - val_acc: 0.9172
Epoch 57/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0692 - acc: 0.8662 - val_loss: 0.9284 - val_acc: 0.9136
Epoch 58/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0384 - acc: 0.8643 - val_loss: 1.5030 - val_acc: 0.9043
Epoch 59/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0105 - acc: 0.8666 - val_loss: 1.1413 - val_acc: 0.9151
Epoch 60/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0855 - acc: 0.8637 - val_loss: 1.2192 - val_acc: 0.9134
Epoch 61/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0577 - acc: 0.8651 - val_loss: 1.0220 - val_acc: 0.9144
Epoch 62/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0458 - acc: 0.8664 - val_loss: 1.2608 - val_acc: 0.9182
Epoch 63/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0662 - acc: 0.8671 - val_loss: 1.1002 - val_acc: 0.9154
Epoch 64/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0679 - acc: 0.8660 - val_loss: 1.1298 - val_acc: 0.9142
Epoch 65/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9849 - acc: 0.8702 - val_loss: 1.0864 - val_acc: 0.9172
Epoch 66/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9759 - acc: 0.8709 - val_loss: 1.2568 - val_acc: 0.9169
Epoch 67/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0351 - acc: 0.8698 - val_loss: 1.0740 - val_acc: 0.9154
Epoch 68/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9850 - acc: 0.8700 - val_loss: 1.5172 - val_acc: 0.8980
Epoch 69/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0379 - acc: 0.8695 - val_loss: 0.9404 - val_acc: 0.9295
Epoch 70/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0501 - acc: 0.8719 - val_loss: 1.1747 - val_acc: 0.9104
Epoch 71/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9713 - acc: 0.8718 - val_loss: 0.8631 - val_acc: 0.9227
Epoch 72/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9529 - acc: 0.8723 - val_loss: 1.1202 - val_acc: 0.9184
Epoch 73/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9970 - acc: 0.8735 - val_loss: 1.1044 - val_acc: 0.9223
Epoch 74/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9704 - acc: 0.8731 - val_loss: 1.2803 - val_acc: 0.9214
Epoch 75/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9653 - acc: 0.8744 - val_loss: 1.0998 - val_acc: 0.9190
Epoch 76/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9772 - acc: 0.8752 - val_loss: 1.1341 - val_acc: 0.9122
Epoch 77/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9926 - acc: 0.8742 - val_loss: 1.3137 - val_acc: 0.9134
Epoch 78/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9730 - acc: 0.8755 - val_loss: 1.3550 - val_acc: 0.9141
Epoch 79/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9847 - acc: 0.8733 - val_loss: 1.3788 - val_acc: 0.9179
Epoch 80/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9683 - acc: 0.8726 - val_loss: 1.0073 - val_acc: 0.9186
Epoch 81/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0107 - acc: 0.8719 - val_loss: 0.8178 - val_acc: 0.9214
Epoch 82/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9780 - acc: 0.8750 - val_loss: 0.9036 - val_acc: 0.9176
Epoch 83/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9653 - acc: 0.8750 - val_loss: 0.9976 - val_acc: 0.9230
Epoch 84/200
469/469 [==============================] - 7s 16ms/step - loss: 1.0043 - acc: 0.8755 - val_loss: 1.0427 - val_acc: 0.9196
Epoch 85/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9754 - acc: 0.8752 - val_loss: 1.2231 - val_acc: 0.9251
Epoch 86/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9696 - acc: 0.8764 - val_loss: 0.9254 - val_acc: 0.9315
Epoch 87/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9607 - acc: 0.8774 - val_loss: 0.9343 - val_acc: 0.9341
Epoch 88/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9504 - acc: 0.8795 - val_loss: 1.2996 - val_acc: 0.9163
Epoch 89/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9482 - acc: 0.8777 - val_loss: 0.9116 - val_acc: 0.9230
Epoch 90/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9474 - acc: 0.8805 - val_loss: 0.9465 - val_acc: 0.9275
Epoch 91/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9492 - acc: 0.8788 - val_loss: 1.1460 - val_acc: 0.9136
Epoch 92/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9356 - acc: 0.8801 - val_loss: 0.9280 - val_acc: 0.9220
Epoch 93/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9451 - acc: 0.8799 - val_loss: 1.3197 - val_acc: 0.9280
Epoch 94/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9399 - acc: 0.8829 - val_loss: 0.9679 - val_acc: 0.9207
Epoch 95/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9367 - acc: 0.8791 - val_loss: 1.0729 - val_acc: 0.9279
Epoch 96/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9161 - acc: 0.8831 - val_loss: 0.7862 - val_acc: 0.9304
Epoch 97/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9580 - acc: 0.8798 - val_loss: 1.3847 - val_acc: 0.9176
Epoch 98/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8997 - acc: 0.8857 - val_loss: 1.6894 - val_acc: 0.9143
Epoch 99/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9099 - acc: 0.8831 - val_loss: 0.8504 - val_acc: 0.9278
Epoch 100/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8900 - acc: 0.8841 - val_loss: 1.1067 - val_acc: 0.9253
Epoch 101/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9159 - acc: 0.8827 - val_loss: 0.9207 - val_acc: 0.9284
Epoch 102/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8698 - acc: 0.8840 - val_loss: 1.2244 - val_acc: 0.9277
Epoch 103/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9159 - acc: 0.8831 - val_loss: 0.9780 - val_acc: 0.9323
Epoch 104/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8906 - acc: 0.8835 - val_loss: 1.1905 - val_acc: 0.9087
Epoch 105/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8991 - acc: 0.8840 - val_loss: 1.0396 - val_acc: 0.9255
Epoch 106/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8674 - acc: 0.8877 - val_loss: 0.8046 - val_acc: 0.9276
Epoch 107/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8829 - acc: 0.8874 - val_loss: 0.8440 - val_acc: 0.9344
Epoch 108/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9597 - acc: 0.8831 - val_loss: 0.9399 - val_acc: 0.9234
Epoch 109/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8764 - acc: 0.8858 - val_loss: 0.9973 - val_acc: 0.9328
Epoch 110/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8605 - acc: 0.8892 - val_loss: 1.2137 - val_acc: 0.9290
Epoch 111/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8709 - acc: 0.8877 - val_loss: 0.9128 - val_acc: 0.9281
Epoch 112/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8728 - acc: 0.8857 - val_loss: 0.7927 - val_acc: 0.9318
Epoch 113/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8876 - acc: 0.8867 - val_loss: 1.0413 - val_acc: 0.9225
Epoch 114/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8767 - acc: 0.8861 - val_loss: 0.8019 - val_acc: 0.9383
Epoch 115/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8672 - acc: 0.8885 - val_loss: 0.9054 - val_acc: 0.9343
Epoch 116/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9029 - acc: 0.8855 - val_loss: 1.2691 - val_acc: 0.9249
Epoch 117/200
469/469 [==============================] - 7s 16ms/step - loss: 0.9016 - acc: 0.8866 - val_loss: 0.7973 - val_acc: 0.9326
Epoch 118/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8727 - acc: 0.8887 - val_loss: 1.3024 - val_acc: 0.8987
Epoch 119/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8312 - acc: 0.8901 - val_loss: 0.9267 - val_acc: 0.9384
Epoch 120/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8998 - acc: 0.8885 - val_loss: 0.9551 - val_acc: 0.9365
Epoch 121/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8648 - acc: 0.8891 - val_loss: 1.1895 - val_acc: 0.9287
Epoch 122/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8468 - acc: 0.8934 - val_loss: 0.7477 - val_acc: 0.9340
Epoch 123/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8375 - acc: 0.8936 - val_loss: 0.9938 - val_acc: 0.9308
Epoch 124/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8835 - acc: 0.8917 - val_loss: 1.0295 - val_acc: 0.9263
Epoch 125/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8570 - acc: 0.8920 - val_loss: 1.4032 - val_acc: 0.9115
Epoch 126/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8829 - acc: 0.8923 - val_loss: 0.8180 - val_acc: 0.9291
Epoch 127/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8561 - acc: 0.8914 - val_loss: 1.0261 - val_acc: 0.9365
Epoch 128/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8319 - acc: 0.8924 - val_loss: 1.0575 - val_acc: 0.9209
Epoch 129/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8410 - acc: 0.8931 - val_loss: 0.8938 - val_acc: 0.9217
Epoch 130/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8531 - acc: 0.8919 - val_loss: 0.9345 - val_acc: 0.9308
Epoch 131/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8322 - acc: 0.8930 - val_loss: 0.9633 - val_acc: 0.9268
Epoch 132/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8652 - acc: 0.8904 - val_loss: 1.0410 - val_acc: 0.9229
Epoch 133/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8245 - acc: 0.8932 - val_loss: 1.0383 - val_acc: 0.9211
Epoch 134/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8232 - acc: 0.8931 - val_loss: 0.8368 - val_acc: 0.9343
Epoch 135/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8470 - acc: 0.8931 - val_loss: 0.7730 - val_acc: 0.9368
Epoch 136/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8319 - acc: 0.8935 - val_loss: 0.8639 - val_acc: 0.9357
Epoch 137/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8428 - acc: 0.8918 - val_loss: 0.9956 - val_acc: 0.9264
Epoch 138/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7995 - acc: 0.8944 - val_loss: 0.9847 - val_acc: 0.9252
Epoch 139/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8204 - acc: 0.8961 - val_loss: 0.8493 - val_acc: 0.9359
Epoch 140/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8218 - acc: 0.8966 - val_loss: 1.0859 - val_acc: 0.9202
Epoch 141/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8028 - acc: 0.8951 - val_loss: 0.8892 - val_acc: 0.9377
Epoch 142/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8177 - acc: 0.8964 - val_loss: 1.1007 - val_acc: 0.9264
Epoch 143/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8078 - acc: 0.8965 - val_loss: 1.0060 - val_acc: 0.9362
Epoch 144/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8514 - acc: 0.8953 - val_loss: 0.8507 - val_acc: 0.9345
Epoch 145/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8152 - acc: 0.8971 - val_loss: 0.6974 - val_acc: 0.9403
Epoch 146/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7741 - acc: 0.8974 - val_loss: 0.7911 - val_acc: 0.9320
Epoch 147/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8024 - acc: 0.8980 - val_loss: 0.7562 - val_acc: 0.9437
Epoch 148/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7928 - acc: 0.8971 - val_loss: 1.0205 - val_acc: 0.9345
Epoch 149/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7965 - acc: 0.8968 - val_loss: 1.1571 - val_acc: 0.9288
Epoch 150/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8307 - acc: 0.8955 - val_loss: 0.7189 - val_acc: 0.9294
Epoch 151/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8202 - acc: 0.8985 - val_loss: 0.8277 - val_acc: 0.9355
Epoch 152/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7832 - acc: 0.8990 - val_loss: 0.7942 - val_acc: 0.9329
Epoch 153/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7860 - acc: 0.8987 - val_loss: 0.8853 - val_acc: 0.9432
Epoch 154/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7857 - acc: 0.8985 - val_loss: 0.9798 - val_acc: 0.9341
Epoch 155/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7900 - acc: 0.8976 - val_loss: 0.9096 - val_acc: 0.9401
Epoch 156/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7918 - acc: 0.8983 - val_loss: 0.8068 - val_acc: 0.9439
Epoch 157/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7855 - acc: 0.9001 - val_loss: 0.7866 - val_acc: 0.9378
Epoch 158/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8225 - acc: 0.8985 - val_loss: 0.8298 - val_acc: 0.9384
Epoch 159/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7707 - acc: 0.9001 - val_loss: 0.9333 - val_acc: 0.9317
Epoch 160/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7743 - acc: 0.9000 - val_loss: 1.0640 - val_acc: 0.9327
Epoch 161/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8030 - acc: 0.9004 - val_loss: 0.9215 - val_acc: 0.9366
Epoch 162/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7667 - acc: 0.9019 - val_loss: 0.8173 - val_acc: 0.9290
Epoch 163/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7584 - acc: 0.9011 - val_loss: 1.1251 - val_acc: 0.9312
Epoch 164/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7673 - acc: 0.9013 - val_loss: 0.7605 - val_acc: 0.9428
Epoch 165/200
469/469 [==============================] - 7s 16ms/step - loss: 0.8057 - acc: 0.9002 - val_loss: 0.7414 - val_acc: 0.9411
Epoch 166/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7771 - acc: 0.9029 - val_loss: 0.8254 - val_acc: 0.9383
Epoch 167/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7347 - acc: 0.9023 - val_loss: 1.1038 - val_acc: 0.9352
Epoch 168/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7756 - acc: 0.9014 - val_loss: 0.9329 - val_acc: 0.9303
Epoch 169/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7892 - acc: 0.9012 - val_loss: 0.8440 - val_acc: 0.9407
Epoch 170/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7432 - acc: 0.9028 - val_loss: 0.9428 - val_acc: 0.9316
Epoch 171/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7599 - acc: 0.9027 - val_loss: 0.8709 - val_acc: 0.9387
Epoch 172/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7813 - acc: 0.9039 - val_loss: 1.3702 - val_acc: 0.9400
Epoch 173/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7676 - acc: 0.9036 - val_loss: 1.1177 - val_acc: 0.9278
Epoch 174/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7634 - acc: 0.9022 - val_loss: 0.8738 - val_acc: 0.9277
Epoch 175/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7441 - acc: 0.9038 - val_loss: 1.2963 - val_acc: 0.9082
Epoch 176/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7578 - acc: 0.9046 - val_loss: 1.1183 - val_acc: 0.9006
Epoch 177/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7729 - acc: 0.9040 - val_loss: 1.3613 - val_acc: 0.9279
Epoch 178/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7583 - acc: 0.9044 - val_loss: 0.9492 - val_acc: 0.9399
Epoch 179/200
469/469 [==============================] - 8s 17ms/step - loss: 0.7398 - acc: 0.9054 - val_loss: 0.8678 - val_acc: 0.9379
Epoch 180/200
469/469 [==============================] - 8s 17ms/step - loss: 0.7818 - acc: 0.9032 - val_loss: 0.6864 - val_acc: 0.9421
Epoch 181/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7597 - acc: 0.9030 - val_loss: 0.8556 - val_acc: 0.9431
Epoch 182/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7215 - acc: 0.9038 - val_loss: 0.9399 - val_acc: 0.9375
Epoch 183/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7536 - acc: 0.9043 - val_loss: 0.7480 - val_acc: 0.9409
Epoch 184/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7686 - acc: 0.9017 - val_loss: 1.0059 - val_acc: 0.9345
Epoch 185/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7452 - acc: 0.9030 - val_loss: 0.8360 - val_acc: 0.9370
Epoch 186/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7735 - acc: 0.9044 - val_loss: 0.9094 - val_acc: 0.9330
Epoch 187/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7357 - acc: 0.9045 - val_loss: 0.8447 - val_acc: 0.9417
Epoch 188/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7726 - acc: 0.9042 - val_loss: 0.9656 - val_acc: 0.9377
Epoch 189/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7324 - acc: 0.9070 - val_loss: 0.6918 - val_acc: 0.9419
Epoch 190/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7414 - acc: 0.9063 - val_loss: 0.7397 - val_acc: 0.9366
Epoch 191/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7388 - acc: 0.9037 - val_loss: 1.0865 - val_acc: 0.9340
Epoch 192/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7354 - acc: 0.9054 - val_loss: 0.7814 - val_acc: 0.9409
Epoch 193/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7646 - acc: 0.9061 - val_loss: 0.8288 - val_acc: 0.9396
Epoch 194/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7232 - acc: 0.9072 - val_loss: 0.8588 - val_acc: 0.9389
Epoch 195/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7216 - acc: 0.9073 - val_loss: 0.8200 - val_acc: 0.9438
Epoch 196/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7259 - acc: 0.9078 - val_loss: 0.8586 - val_acc: 0.9377
Epoch 197/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7196 - acc: 0.9072 - val_loss: 0.7757 - val_acc: 0.9361
Epoch 198/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7192 - acc: 0.9079 - val_loss: 1.0647 - val_acc: 0.9339
Epoch 199/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7242 - acc: 0.9093 - val_loss: 0.6509 - val_acc: 0.9403
Epoch 200/200
469/469 [==============================] - 7s 16ms/step - loss: 0.7152 - acc: 0.9081 - val_loss: 0.7299 - val_acc: 0.9407
Test score: 0.7299376726150513
Test accuracy: 0.9406999945640564
D:\anaconda\envs\anyushi\lib\site-packages\numpy\lib\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr = np.asanyarray(arr)
0
[[ 15.  -22.5 -21.5 -18.  -21.  -18.5 -12.  -12.   -9.5  -9. ]]
0
[[ 16.  -20.5 -12.5 -18.  -25.  -18.5 -14.  -14.  -18.5 -11. ]]
0
[[ 14.  -22.5 -15.5 -16.  -22.  -18.5 -15.  -12.  -13.5  -6. ]]
0
[[ 18.  -25.5 -20.5 -19.  -23.  -16.5 -14.  -13.  -12.5 -10. ]]
0
[[ 18.  -21.5 -17.5 -18.  -26.  -18.5 -16.  -16.  -13.5  -8. ]]
0
[[ 15.  -22.5 -14.5 -20.  -27.  -17.5 -15.  -16.  -18.5 -10. ]]
0
[[ 15.5 -23.  -19.  -20.5 -23.5 -18.  -14.5 -14.5 -17.  -10.5]]
0
[[ 18.  -22.5 -17.5 -19.  -26.  -18.5 -15.  -16.  -14.5  -9. ]]
0
[[ 16.  -23.5 -14.5 -16.  -27.  -19.5 -17.  -16.  -13.5  -9. ]]
0
[[ 12.  -23.5  -6.5 -11.  -24.  -15.5 -21.  -15.  -16.5  -7. ]]
0
[[ 17.5 -22.  -16.  -18.5 -24.5 -17.  -16.5 -13.5 -17.   -8.5]]
0
[[ 15.5 -24.  -20.  -19.5 -23.5 -17.  -15.5 -15.5 -16.  -10.5]]
0
[[ 14.5 -25.  -19.  -17.5 -21.5 -18.  -15.5 -12.5 -13.   -9.5]]
0
[[ 15.5 -22.  -17.  -19.5 -25.5 -16.  -14.5 -16.5 -18.   -9.5]]
0
[[ 16.  -24.5 -15.5 -17.  -25.  -18.5 -15.  -15.  -16.5 -10. ]]
0
[[ 17.5 -26.  -18.  -17.5 -23.5 -20.  -16.5 -15.5 -13.  -11.5]]
0
[[ 17.5 -24.  -13.  -19.5 -25.5 -19.  -16.5 -14.5 -16.   -9.5]]
0
[[ 15.  -22.5 -15.5 -13.  -26.  -19.5 -17.  -15.  -13.5  -7. ]]
0
[[ 16.5 -22.  -17.  -19.5 -24.5 -18.  -15.5 -15.5 -16.   -9.5]]
0
[[ 13.  -20.5 -12.5 -14.  -23.  -15.5 -19.  -12.  -15.5  -7. ]]
1
[[-11.    7.5 -17.5 -10.  -18.  -16.5 -18.  -26.  -19.5 -19. ]]
1
[[ -9.5   7.  -17.  -11.5 -19.5 -18.  -19.5 -26.5 -20.  -17.5]]
1
[[ -8.5   7.  -16.  -10.5 -23.5 -19.  -22.5 -23.5 -20.  -20.5]]
1
[[-17.5   6.  -11.  -14.5 -13.5 -18.  -18.5 -21.5 -17.  -22.5]]
1
[[-14.    8.5 -14.5 -14.  -18.  -18.5 -16.  -23.  -18.5 -19. ]]
1
[[-15.    5.5 -15.5 -16.  -20.  -19.5 -16.  -23.  -20.5 -21. ]]
1
[[-13.    8.5 -13.5 -13.  -20.  -16.5 -20.  -23.  -20.5 -20. ]]
1
[[-14.5   9.  -15.  -13.5 -19.5 -18.  -16.5 -23.5 -19.  -19.5]]
1
[[ -8.5   7.  -16.   -6.5 -19.5 -17.  -20.5 -23.5 -19.  -15.5]]
1
[[-12.    8.5 -16.5 -12.  -20.  -17.5 -17.  -24.  -21.5 -18. ]]
1
[[-12.    6.5 -16.5 -11.  -19.  -18.5 -17.  -24.  -19.5 -20. ]]
1
[[-11.    7.5 -19.5 -12.  -19.  -20.5 -20.  -25.  -20.5 -20. ]]
1
[[-11.5   7.  -19.  -11.5 -18.5 -19.  -17.5 -25.5 -22.  -19.5]]
1
[[-10.5   7.  -18.  -12.5 -21.5 -19.  -19.5 -26.5 -21.  -20.5]]
1
[[-17.    7.5 -15.5 -15.  -20.  -19.5 -20.  -19.  -21.5 -22. ]]
1
[[-10.    9.5 -16.5 -15.  -20.  -20.5 -22.  -25.  -18.5 -19. ]]
1
[[-11.5   6.  -19.  -12.5 -20.5 -20.  -19.5 -24.5 -21.  -19.5]]
1
[[-14.    6.5 -15.5 -14.  -21.  -20.5 -17.  -22.  -21.5 -23. ]]
1
[[-10.5   7.  -18.  -11.5 -19.5 -20.  -18.5 -24.5 -20.  -19.5]]
1
[[-10.5   9.  -17.  -11.5 -19.5 -20.  -18.5 -24.5 -20.  -18.5]]
2
[[-17.5 -24.   -6.  -16.5 -17.5 -31.  -26.5  12.5  -3.   -9.5]]
2
[[-14.  -15.5  10.5 -11.  -30.  -22.5 -33.  -12.  -12.5 -21. ]]
2
[[-14.5 -17.    7.  -15.5 -32.5 -35.  -29.5 -14.5  -6.  -13.5]]
2
[[-13.5 -16.    9.  -13.5 -30.5 -28.  -26.5 -15.5 -15.  -24.5]]
2
[[-14.  -15.5  11.5 -17.  -34.  -27.5 -27.  -12.  -10.5 -20. ]]
2
[[-13.5 -17.   10.  -13.5 -29.5 -28.  -27.5 -16.5 -16.  -23.5]]
2
[[ 15.5 -18.  -16.  -18.5 -26.5 -21.  -15.5 -13.5 -17.  -10.5]]
2
[[-14.5 -21.   10.  -16.5 -30.5 -34.  -28.5 -17.5 -15.  -24.5]]
2
[[-13.5 -20.   12.  -17.5 -30.5 -34.  -28.5 -15.5 -16.  -25.5]]
2
[[-11.5 -18.   12.  -21.5 -33.5 -26.  -22.5 -17.5 -15.  -18.5]]
2
[[-16.  -19.5  11.5 -18.  -23.  -27.5 -25.  -15.  -14.5 -28. ]]
2
[[-15.5 -20.    8.  -17.5 -26.5 -25.  -27.5 -12.5 -16.  -30.5]]
2
[[-17.5 -18.   13.  -13.5 -28.5 -27.  -24.5 -17.5 -15.  -26.5]]
2
[[-13.5 -16.    8.  -13.5 -34.5 -28.  -26.5 -12.5 -14.  -20.5]]
2
[[-14.5 -13.    8.  -13.5 -34.5 -34.  -25.5  -8.5  -7.  -16.5]]
2
[[-13.5 -18.    9.  -13.5 -30.5 -30.  -29.5 -12.5 -15.  -23.5]]
2
[[-16.5 -20.   12.  -16.5 -31.5 -29.  -30.5 -13.5 -17.  -23.5]]
2
[[-13.5 -23.   13.  -14.5 -17.5 -24.  -22.5 -11.5 -13.  -30.5]]
2
[[-15.  -17.5  13.5 -18.  -23.  -27.5 -25.  -16.  -14.5 -27. ]]
2
[[-13.5 -21.  -10.    3.5 -22.5   7.   -9.5 -18.5 -13.  -15.5]]
3
[[-17.5 -22.  -13.   13.5 -21.5 -18.  -27.5 -21.5   0.  -12.5]]
3
[[-20.  -25.5 -11.5  17.  -20.  -15.5 -24.  -25.   -7.5 -17. ]]
3
[[-16.5 -24.  -11.   19.5 -24.5 -16.  -28.5 -16.5  -3.  -19.5]]
3
[[-11.5 -19.  -10.   10.5 -25.5  -5.  -28.5 -21.5 -10.  -11.5]]
3
[[-17.5 -25.  -13.   16.5 -20.5 -18.  -24.5 -19.5  -1.  -17.5]]
3
[[-19.5 -15.  -12.    8.5 -22.5 -21.  -32.5 -20.5  -2.  -12.5]]
3
[[-16.  -25.5 -13.5  17.  -22.  -17.5 -29.  -19.   -3.5 -21. ]]
3
[[-16.  -23.5 -13.5  16.  -19.  -16.5 -24.  -20.   -6.5 -11. ]]
3
[[-21.  -26.5 -11.5  18.  -20.  -13.5 -28.  -24.   -2.5 -15. ]]
3
[[-17.5 -26.  -15.   11.5 -20.5 -19.  -28.5 -20.5  -2.  -11.5]]
3
[[-18.5 -24.  -10.   18.5 -24.5 -16.  -28.5 -16.5  -2.  -17.5]]
3
[[-18.5 -25.  -12.   20.5 -19.5 -15.  -24.5 -18.5  -4.  -13.5]]
3
[[-19.  -23.5  -8.5   9.  -23.  -10.5 -24.  -22.   -9.5 -16. ]]
3
[[-11.  -20.5  -9.5   8.  -25.   -7.5 -24.  -19.  -10.5 -12. ]]
3
[[-14.  -15.5  -2.5   7.  -26.  -12.5 -27.  -21.  -12.5 -22. ]]
3
[[-20.5 -18.   -7.    1.5 -29.5 -23.  -23.5 -25.5   1.  -14.5]]
3
[[-22.  -25.5 -12.5  18.  -21.  -12.5 -26.  -23.   -5.5 -18. ]]
3
[[ -6.5 -22.    1.   -2.5 -32.5   0.  -25.5 -17.5 -16.  -11.5]]
3
[[-16.  -25.5 -12.5   7.  -18.   -3.5 -27.  -19.   -5.5   1. ]]
3
[[-17.5 -24.  -14.    5.5 -23.5 -11.  -26.5 -23.5  -6.   -3.5]]
4
[[-16.5 -15.  -19.  -14.5  15.5 -13.   -5.5 -19.5 -11.  -16.5]]
4
[[-16.5 -17.  -21.  -21.5  11.5 -18.   -9.5 -16.5 -13.  -15.5]]
4
[[-20.  -10.5 -25.5 -12.   12.  -16.5  -1.  -13.   -0.5  -6. ]]
4
[[-15.  -15.5 -20.5 -17.   18.  -14.5  -8.  -20.  -10.5 -16. ]]
4
[[-16.5 -13.  -19.  -14.5  22.5 -12.   -6.5 -18.5  -5.  -14.5]]
4
[[-16.5 -19.  -21.  -17.5  15.5 -15.   -7.5 -18.5 -16.  -19.5]]
4
[[-17.5 -18.  -26.  -16.5  17.5 -14.   -7.5 -22.5 -17.  -19.5]]
4
[[-17.  -21.5 -15.5 -20.    8.  -17.5  -1.  -18.  -16.5 -16. ]]
4
[[-13.5 -17.  -18.  -17.5   2.5 -11.   -5.5  -5.5  -5.   -6.5]]
4
[[-19.  -15.5 -20.5 -15.   19.  -16.5  -6.  -23.  -12.5 -19. ]]
4
[[-17.5 -17.  -23.  -17.5  16.5 -14.   -6.5 -22.5 -17.  -18.5]]
4
[[-16.5  -6.  -25.   -7.5  10.5 -11.   -7.5 -20.5  -6.    1.5]]
4
[[-16.  -20.5 -19.5 -19.   11.  -16.5  -7.  -19.  -17.5 -17. ]]
4
[[-19.  -18.5 -21.5 -12.   19.  -15.5 -10.  -23.  -14.5 -18. ]]
4
[[-15.5 -12.  -21.  -11.5  16.5 -10.   -7.5 -21.5  -9.  -14.5]]
4
[[-18.5 -17.  -20.  -18.5   8.5 -18.   -9.5 -14.5 -15.  -13.5]]
4
[[-17.  -16.5 -23.5 -17.   17.  -15.5  -9.  -21.  -13.5 -18. ]]
4
[[-18.5 -17.  -21.  -16.5  19.5 -18.   -7.5 -22.5 -14.  -18.5]]
4
[[-19.5  -8.  -13.   -6.5   5.5 -19.   -7.5 -10.5  -5.  -17.5]]
4
[[-15.5 -15.  -21.  -14.5  17.5 -11.   -9.5 -19.5  -9.  -15.5]]
5
[[-17.  -12.5 -14.5  -4.  -23.   14.5  -7.  -25.  -20.5  -9. ]]
5
[[-17.  -19.5  -7.5  -4.  -27.   14.5 -14.  -24.  -22.5 -18. ]]
5
[[ -4.  -13.5 -19.5  -9.  -21.   13.5  -3.  -12.  -19.5 -14. ]]
5
[[ -7.   -9.5 -15.5  -9.  -22.   13.5  -2.  -14.  -21.5 -11. ]]
5
[[-11.5 -17.   -5.  -11.5 -32.5  14.  -13.5 -22.5 -22.   -9.5]]
5
[[-10.  -19.5 -11.5  -5.  -30.   17.5  -8.  -16.  -21.5  -9. ]]
5
[[ -7.5 -14.  -17.   -7.5 -18.5  17.   -2.5 -12.5 -24.  -13.5]]
5
[[ -4.  -12.5 -17.5 -12.  -22.   16.5   0.   -9.  -18.5 -14. ]]
5
[[ -8.5 -16.  -11.   -4.5 -25.5  20.  -15.5 -18.5 -24.   -7.5]]
5
[[-14.  -16.5 -12.5  -6.  -25.   18.5 -11.  -22.  -21.5  -6. ]]
5
[[-10.  -19.5  -6.5  -6.  -31.   18.5 -17.  -20.  -26.5 -10. ]]
5
[[-11.  -18.5 -10.5 -11.  -29.   20.5 -13.  -20.  -27.5  -5. ]]
5
[[ -9.  -13.5  -6.5  -4.  -26.   18.5 -14.  -22.  -21.5  -7. ]]
5
[[-11.  -17.5 -21.5  -8.  -15.   19.5  -1.  -15.  -22.5 -10. ]]
5
[[-14.  -17.5 -12.5  -9.  -26.   22.5 -13.  -21.  -25.5  -5. ]]
5
[[-13.  -14.5  -8.5  -7.  -28.   23.5 -12.  -22.  -22.5  -8. ]]
5
[[ -9.5 -19.   -9.   -6.5 -27.5  20.  -12.5 -21.5 -23.  -13.5]]
5
[[-10.5 -15.  -12.   -5.5 -23.5  18.   -5.5 -25.5 -21.   -9.5]]
5
[[-11.  -20.5 -11.5  -8.  -28.   19.5 -15.  -19.  -26.5  -4. ]]
5
[[-10.5 -18.   -6.   -5.5 -25.5  21.  -14.5 -19.5 -26.   -6.5]]
6
[[-14.  -14.5 -22.5 -10.  -10.  -20.5  21.  -24.   -9.5 -19. ]]
6
[[-11.5  -9.  -26.  -14.5  -6.5 -17.   18.5 -18.5  -9.  -20.5]]
6
[[-16.5 -17.  -21.  -13.5 -17.5 -16.   19.5 -26.5 -14.  -23.5]]
6
[[-10.5 -15.  -27.   -8.5 -14.5 -19.   18.5 -26.5 -11.  -24.5]]
6
[[ -9.5  -9.  -28.  -10.5  -8.5 -10.   17.5 -23.5  -9.  -19.5]]
6
[[-17.  -17.5 -18.5  -9.  -13.  -16.5  22.  -26.  -12.5 -24. ]]
6
[[-14.  -14.5 -17.5 -12.  -16.  -20.5  20.  -24.  -17.5 -19. ]]
6
[[-17.  -12.5 -19.5 -13.  -15.  -18.5  20.  -28.  -14.5 -24. ]]
6
[[-14.  -12.5 -22.5 -13.  -18.  -19.5  23.  -27.  -17.5 -21. ]]
6
[[-15.5 -17.  -22.  -12.5 -17.5 -20.   23.5 -27.5 -14.  -23.5]]
6
[[-14.  -11.5 -20.5 -13.  -16.  -20.5  20.  -25.  -17.5 -22. ]]
6
[[-13.5 -12.  -22.  -12.5 -18.5 -20.   21.5 -26.5 -18.  -22.5]]
6
[[-16.  -16.5 -21.5 -11.  -17.  -18.5  22.  -26.  -14.5 -23. ]]
6
[[-14.  -14.5 -20.5 -12.  -17.  -19.5  23.  -28.  -14.5 -22. ]]
6
[[-11.   -9.5 -19.5 -15.  -16.  -19.5  22.  -27.  -16.5 -22. ]]
6
[[-12.5 -18.  -26.  -13.5 -19.5 -17.   18.5 -27.5 -15.  -24.5]]
6
[[-14.5 -13.  -19.  -12.5 -17.5 -18.   22.5 -27.5 -14.  -21.5]]
6
[[-13.5 -15.  -25.  -14.5 -18.5 -15.   20.5 -25.5 -17.  -24.5]]
6
[[-14.5 -14.  -17.  -13.5 -13.5 -19.   18.5 -24.5 -18.  -19.5]]
6
[[-13.  -16.5 -21.5 -11.  -15.  -18.5  23.  -28.  -12.5 -20. ]]
7
[[-20.5 -25.  -10.  -15.5 -17.5 -26.  -26.5  11.5  -5.  -12.5]]
7
[[-19.5 -23.  -12.  -14.5 -14.5 -22.  -21.5  13.5  -6.  -10.5]]
7
[[-19.5 -23.   -9.   -9.5 -18.5 -26.  -29.5   6.5  -6.  -11.5]]
7
[[-20.5 -21.  -14.  -10.5 -12.5 -18.  -19.5  11.5  -3.  -12.5]]
7
[[-20.  -23.5  -7.5 -17.  -16.  -29.5 -28.   14.   -8.5 -14. ]]
7
[[-20.  -21.5 -10.5 -16.  -18.  -22.5 -28.   17.   -6.5 -13. ]]
7
[[-18.5 -22.  -10.  -15.5 -15.5 -21.  -22.5  16.5  -6.  -14.5]]
7
[[-17.5 -22.   -8.  -16.5 -14.5 -22.  -24.5  17.5  -8.  -13.5]]
7
[[-19.5 -22.  -10.  -18.5 -18.5 -24.  -27.5  15.5  -6.  -13.5]]
7
[[-19.  -22.5  -7.5 -16.  -20.  -22.5 -26.   14.   -3.5 -13. ]]
7
[[-19.  -25.5 -13.5 -17.  -15.  -23.5 -23.   13.   -7.5 -15. ]]
7
[[-19.5 -22.   -8.  -18.5 -17.5 -26.  -26.5  11.5  -7.  -14.5]]
7
[[-19.5 -24.   -8.  -16.5 -17.5 -26.  -25.5  13.5  -5.  -13.5]]
7
[[-19.  -21.5  -8.5 -17.  -16.  -26.5 -27.   15.   -6.5 -14. ]]
7
[[-20.  -21.5 -10.5 -15.  -16.  -25.5 -25.   16.   -5.5 -16. ]]
7
[[-20.5 -22.   -9.  -15.5 -18.5 -23.  -25.5  15.5  -6.  -14.5]]
7
[[-19.  -23.5  -8.5 -14.  -19.  -24.5 -27.    9.   -3.5 -11. ]]
7
[[-18.  -23.5 -13.5 -14.  -14.  -20.5 -21.   12.   -5.5 -10. ]]
7
[[-19.  -24.5 -12.5 -15.  -14.  -20.5 -21.   12.   -7.5 -13. ]]
7
[[-15.  -24.5 -12.5 -16.  -13.  -22.5 -25.   16.   -5.5 -10. ]]
8
[[-13.  -16.5 -14.5  -9.  -23.  -28.5 -19.  -22.   12.5  -7. ]]
8
[[-10.   -9.5 -17.5 -11.  -21.  -20.5 -16.  -15.   11.5  -7. ]]
8
[[ -2.5 -12.  -14.  -16.5 -21.5 -23.  -16.5 -16.5  12.   -5.5]]
8
[[-10.5 -13.  -16.  -10.5 -26.5 -23.  -17.5 -19.5  14.   -6.5]]
8
[[ -6.  -14.5 -14.5 -14.  -22.  -24.5 -19.  -18.   14.5  -1. ]]
8
[[ -7.5 -12.  -16.  -12.5 -24.5 -22.  -19.5 -13.5  10.   -5.5]]
8
[[-14.5 -10.  -17.   -6.5 -20.5 -19.  -11.5 -20.5   9.   -6.5]]
8
[[-18.  -10.5 -17.5  -9.  -23.  -24.5 -15.  -22.   12.5  -8. ]]
8
[[ -5.  -21.5 -12.5 -14.  -26.  -20.5  -6.  -20.    9.5  -2. ]]
8
[[-12.  -12.5 -17.5 -10.  -28.  -22.5 -13.  -21.   11.5  -7. ]]
8
[[-10.  -17.5 -11.5 -15.  -24.  -18.5 -11.  -20.   10.5  -7. ]]
8
[[-15.  -13.5  -8.5 -19.  -24.  -22.5  -7.  -25.   14.5  -5. ]]
8
[[-13.  -13.5 -19.5 -11.  -24.  -20.5 -12.  -22.   15.5  -3. ]]
8
[[-13.  -13.5 -17.5 -14.  -24.  -21.5 -15.  -22.   14.5  -4. ]]
8
[[-14.  -13.5 -16.5 -14.  -22.  -21.5 -13.  -21.   14.5  -5. ]]
8
[[ -6.5 -14.  -20.   -4.5 -18.5   2.    1.5 -17.5  -9.   -9.5]]
8
[[-16.   -9.5 -16.5 -12.  -27.  -22.5 -15.  -22.    8.5  -9. ]]
8
[[-15.  -11.5 -14.5 -13.  -28.  -23.5 -16.  -21.    5.5 -10. ]]
8
[[ -5.  -15.5 -13.5 -11.  -26.  -19.5 -11.  -17.   13.5  -1. ]]
8
[[-14.  -14.5 -17.5 -15.  -24.  -23.5 -13.  -23.   15.5  -5. ]]
9
[[-16.  -18.5 -21.5 -19.    4.  -18.5 -12.   -6.  -10.5  -4. ]]
9
[[-13.  -16.5 -19.5 -20.    9.  -19.5  -5.  -15.   -9.5  -8. ]]
9
[[-15.  -20.5 -15.5 -10.   -9.  -12.5 -20.   -6.   -6.5   4. ]]
9
[[-17.  -17.5 -18.5 -12.  -12.  -19.5 -19.    2.   -6.5  -4. ]]
9
[[-14.  -17.5 -13.5  -8.  -13.   -6.5 -18.  -20.   -5.5  12. ]]
9
[[-18.5 -16.  -14.   -6.5  -5.5 -16.  -15.5 -24.5  -7.    9.5]]
9
[[ -9.5 -17.   -9.  -17.5  -3.5 -20.   -9.5 -15.5  -4.    3.5]]
9
[[-13.  -14.5 -16.5  -8.  -10.   -8.5 -19.  -24.   -8.5  10. ]]
9
[[-20.5 -16.  -18.   -9.5  -6.5 -17.  -15.5 -25.5  -9.    8.5]]
9
[[-19.  -16.5 -17.5  -8.  -10.  -19.5 -21.  -21.   -5.5   8. ]]
9
[[-19.5 -15.  -14.   -7.5  -7.5 -15.  -17.5 -20.5  -5.    9.5]]
9
[[-19.  -16.5 -15.5  -8.   -9.  -18.5 -19.  -21.   -5.5  10. ]]
9
[[-15.5  -9.  -16.   -8.5  -6.5  -6.  -17.5 -24.5  -9.   11.5]]
9
[[-18.  -13.5 -13.5  -8.   -6.  -13.5 -14.  -21.   -6.5   9. ]]
9
[[-17.  -13.5 -18.5 -10.   -3.  -14.5 -13.  -25.   -8.5   3. ]]
9
[[-20.5 -13.  -12.   -9.5  -7.5 -13.  -16.5 -22.5  -4.   11.5]]
9
[[-20.5 -10.  -12.   -7.5  -5.5 -14.  -13.5 -19.5  -1.    5.5]]
9
[[-23.  -15.5 -10.5 -12.   -9.  -19.5 -22.  -15.   -4.5   7. ]]
9
[[-19.  -15.5 -11.5 -13.    1.  -18.5  -9.   -3.   -1.5   1. ]]
9
[[-21.5 -13.  -12.   -9.5  -5.5 -16.  -15.5 -14.5  -5.   10.5]]

进程已结束,退出代码0
