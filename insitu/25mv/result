D:\anaconda3\envs\anyushi\python.exe D:/anyushi/deeplearning/zian/untitled1/ttest2.py
2022-02-02 10:40:15.661504: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
60000 train samples
10000 test samples
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
drop0 (DropoutNoScale)       (None, 784)               0
_________________________________________________________________
dense1 (BinaryDense1)        (None, 512)               401920
_________________________________________________________________
act1 (Activation)            (None, 512)               0
_________________________________________________________________
drop1 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense2 (BinaryDense2)        (None, 512)               262656
_________________________________________________________________
act2 (Activation)            (None, 512)               0
_________________________________________________________________
drop2 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense3 (BinaryDense3)        (None, 512)               262656
_________________________________________________________________
act3 (Activation)            (None, 512)               0
_________________________________________________________________
drop3 (DropoutNoScale)       (None, 512)               0
_________________________________________________________________
dense (BinaryDense)          (None, 10)                5130
=================================================================
Total params: 932,362
Trainable params: 930,816
Non-trainable params: 1,546
_________________________________________________________________
Epoch 1/200
469/469 [==============================] - 8s 17ms/step - loss: 2.2819 - acc: 0.6424 - val_loss: 1.3373 - val_acc: 0.8404
Epoch 2/200
469/469 [==============================] - 8s 17ms/step - loss: 1.1534 - acc: 0.7312 - val_loss: 1.1362 - val_acc: 0.8420
Epoch 3/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1421 - acc: 0.7307 - val_loss: 1.2640 - val_acc: 0.8252
Epoch 4/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1461 - acc: 0.7364 - val_loss: 1.2510 - val_acc: 0.8406
Epoch 5/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2093 - acc: 0.7376 - val_loss: 1.4125 - val_acc: 0.8439
Epoch 6/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3015 - acc: 0.7421 - val_loss: 1.4166 - val_acc: 0.8535
Epoch 7/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3206 - acc: 0.7524 - val_loss: 1.6333 - val_acc: 0.8259
Epoch 8/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4342 - acc: 0.7553 - val_loss: 1.9668 - val_acc: 0.8525
Epoch 9/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4706 - acc: 0.7578 - val_loss: 1.8024 - val_acc: 0.8386
Epoch 10/200
469/469 [==============================] - 8s 17ms/step - loss: 1.4824 - acc: 0.7701 - val_loss: 2.4202 - val_acc: 0.8327
Epoch 11/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5484 - acc: 0.7711 - val_loss: 2.7112 - val_acc: 0.8217
Epoch 12/200
469/469 [==============================] - 8s 16ms/step - loss: 1.6435 - acc: 0.7718 - val_loss: 1.7331 - val_acc: 0.8611
Epoch 13/200
469/469 [==============================] - 8s 16ms/step - loss: 1.6178 - acc: 0.7727 - val_loss: 2.1801 - val_acc: 0.8485
Epoch 14/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5734 - acc: 0.7807 - val_loss: 1.7348 - val_acc: 0.8531
Epoch 15/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5324 - acc: 0.7831 - val_loss: 1.7612 - val_acc: 0.8578
Epoch 16/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5869 - acc: 0.7905 - val_loss: 1.9447 - val_acc: 0.8584
Epoch 17/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5803 - acc: 0.7906 - val_loss: 2.0924 - val_acc: 0.8522
Epoch 18/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5956 - acc: 0.7900 - val_loss: 2.9806 - val_acc: 0.8247
Epoch 19/200
469/469 [==============================] - 8s 16ms/step - loss: 1.6006 - acc: 0.7932 - val_loss: 1.6440 - val_acc: 0.8808
Epoch 20/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4789 - acc: 0.7997 - val_loss: 1.3783 - val_acc: 0.8832
Epoch 21/200
469/469 [==============================] - 8s 17ms/step - loss: 1.5037 - acc: 0.8043 - val_loss: 2.1172 - val_acc: 0.8718
Epoch 22/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5466 - acc: 0.8027 - val_loss: 1.9093 - val_acc: 0.8580
Epoch 23/200
469/469 [==============================] - 8s 17ms/step - loss: 1.4950 - acc: 0.8081 - val_loss: 1.6032 - val_acc: 0.8741
Epoch 24/200
469/469 [==============================] - 8s 17ms/step - loss: 1.4948 - acc: 0.8090 - val_loss: 1.4067 - val_acc: 0.8702
Epoch 25/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4423 - acc: 0.8127 - val_loss: 1.7470 - val_acc: 0.8752
Epoch 26/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4254 - acc: 0.8149 - val_loss: 2.2917 - val_acc: 0.8570
Epoch 27/200
469/469 [==============================] - 8s 16ms/step - loss: 1.5102 - acc: 0.8146 - val_loss: 2.1695 - val_acc: 0.8842
Epoch 28/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4818 - acc: 0.8162 - val_loss: 1.4212 - val_acc: 0.8868
Epoch 29/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4047 - acc: 0.8198 - val_loss: 1.6985 - val_acc: 0.8809
Epoch 30/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4157 - acc: 0.8203 - val_loss: 1.7749 - val_acc: 0.8931
Epoch 31/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4673 - acc: 0.8211 - val_loss: 1.9195 - val_acc: 0.8752
Epoch 32/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4282 - acc: 0.8225 - val_loss: 1.4731 - val_acc: 0.8935
Epoch 33/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3508 - acc: 0.8271 - val_loss: 1.6520 - val_acc: 0.8849
Epoch 34/200
469/469 [==============================] - 8s 16ms/step - loss: 1.4041 - acc: 0.8266 - val_loss: 1.3111 - val_acc: 0.8991
Epoch 35/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3180 - acc: 0.8314 - val_loss: 1.9158 - val_acc: 0.8508
Epoch 36/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3487 - acc: 0.8306 - val_loss: 1.3790 - val_acc: 0.8820
Epoch 37/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3250 - acc: 0.8367 - val_loss: 1.9621 - val_acc: 0.8896
Epoch 38/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3530 - acc: 0.8311 - val_loss: 1.5043 - val_acc: 0.8896
Epoch 39/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3406 - acc: 0.8353 - val_loss: 1.4320 - val_acc: 0.8942
Epoch 40/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3186 - acc: 0.8341 - val_loss: 1.4925 - val_acc: 0.8963
Epoch 41/200
469/469 [==============================] - 8s 16ms/step - loss: 1.3183 - acc: 0.8373 - val_loss: 1.9275 - val_acc: 0.8957
Epoch 42/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2697 - acc: 0.8375 - val_loss: 1.1799 - val_acc: 0.8974
Epoch 43/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2592 - acc: 0.8384 - val_loss: 1.7206 - val_acc: 0.8990
Epoch 44/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2951 - acc: 0.8404 - val_loss: 1.5507 - val_acc: 0.8902
Epoch 45/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2495 - acc: 0.8430 - val_loss: 1.4198 - val_acc: 0.8988
Epoch 46/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2545 - acc: 0.8431 - val_loss: 1.7033 - val_acc: 0.8840
Epoch 47/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2843 - acc: 0.8410 - val_loss: 1.5058 - val_acc: 0.8954
Epoch 48/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2648 - acc: 0.8418 - val_loss: 1.2064 - val_acc: 0.9093
Epoch 49/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2298 - acc: 0.8448 - val_loss: 2.0889 - val_acc: 0.8869
Epoch 50/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2792 - acc: 0.8446 - val_loss: 1.9034 - val_acc: 0.8770
Epoch 51/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2560 - acc: 0.8464 - val_loss: 1.5863 - val_acc: 0.9069
Epoch 52/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1569 - acc: 0.8498 - val_loss: 1.1954 - val_acc: 0.8966
Epoch 53/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2280 - acc: 0.8483 - val_loss: 1.8976 - val_acc: 0.9038
Epoch 54/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2562 - acc: 0.8463 - val_loss: 1.2468 - val_acc: 0.9037
Epoch 55/200
469/469 [==============================] - 8s 16ms/step - loss: 1.2046 - acc: 0.8479 - val_loss: 1.5203 - val_acc: 0.9023
Epoch 56/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1895 - acc: 0.8515 - val_loss: 1.4619 - val_acc: 0.8886
Epoch 57/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1383 - acc: 0.8542 - val_loss: 1.7788 - val_acc: 0.8830
Epoch 58/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1854 - acc: 0.8536 - val_loss: 1.5037 - val_acc: 0.8933
Epoch 59/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1689 - acc: 0.8533 - val_loss: 1.1264 - val_acc: 0.9111
Epoch 60/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1916 - acc: 0.8542 - val_loss: 1.3023 - val_acc: 0.8988
Epoch 61/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1140 - acc: 0.8561 - val_loss: 1.0639 - val_acc: 0.8795
Epoch 62/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1305 - acc: 0.8551 - val_loss: 1.8211 - val_acc: 0.8902
Epoch 63/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1433 - acc: 0.8568 - val_loss: 1.2543 - val_acc: 0.9028
Epoch 64/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1835 - acc: 0.8559 - val_loss: 1.4810 - val_acc: 0.9023
Epoch 65/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1472 - acc: 0.8562 - val_loss: 1.2625 - val_acc: 0.9069
Epoch 66/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1311 - acc: 0.8580 - val_loss: 1.6442 - val_acc: 0.9097
Epoch 67/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1602 - acc: 0.8554 - val_loss: 1.6081 - val_acc: 0.8980
Epoch 68/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1397 - acc: 0.8581 - val_loss: 1.2850 - val_acc: 0.9116
Epoch 69/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1198 - acc: 0.8616 - val_loss: 1.4775 - val_acc: 0.8927
Epoch 70/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0933 - acc: 0.8611 - val_loss: 1.3309 - val_acc: 0.9076
Epoch 71/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1155 - acc: 0.8630 - val_loss: 1.2383 - val_acc: 0.9065
Epoch 72/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1107 - acc: 0.8603 - val_loss: 1.8993 - val_acc: 0.8967
Epoch 73/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1125 - acc: 0.8622 - val_loss: 1.1099 - val_acc: 0.9198
Epoch 74/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1005 - acc: 0.8609 - val_loss: 1.0585 - val_acc: 0.9176
Epoch 75/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0942 - acc: 0.8651 - val_loss: 1.5949 - val_acc: 0.8918
Epoch 76/200
469/469 [==============================] - 8s 16ms/step - loss: 1.1032 - acc: 0.8616 - val_loss: 1.9729 - val_acc: 0.8641
Epoch 77/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0471 - acc: 0.8664 - val_loss: 0.9506 - val_acc: 0.9171
Epoch 78/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0371 - acc: 0.8698 - val_loss: 1.4051 - val_acc: 0.9005
Epoch 79/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0195 - acc: 0.8666 - val_loss: 1.6204 - val_acc: 0.9013
Epoch 80/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0550 - acc: 0.8683 - val_loss: 1.3144 - val_acc: 0.9037
Epoch 81/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0961 - acc: 0.8671 - val_loss: 1.3239 - val_acc: 0.9075
Epoch 82/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0491 - acc: 0.8694 - val_loss: 2.5021 - val_acc: 0.8873
Epoch 83/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0465 - acc: 0.8696 - val_loss: 1.5987 - val_acc: 0.8979
Epoch 84/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0252 - acc: 0.8699 - val_loss: 1.0128 - val_acc: 0.9130
Epoch 85/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0432 - acc: 0.8664 - val_loss: 1.3358 - val_acc: 0.9098
Epoch 86/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0476 - acc: 0.8689 - val_loss: 1.2408 - val_acc: 0.9178
Epoch 87/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0059 - acc: 0.8714 - val_loss: 1.1861 - val_acc: 0.9134
Epoch 88/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0190 - acc: 0.8732 - val_loss: 1.1028 - val_acc: 0.9200
Epoch 89/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0080 - acc: 0.8707 - val_loss: 1.0283 - val_acc: 0.9166
Epoch 90/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0563 - acc: 0.8724 - val_loss: 1.0120 - val_acc: 0.9208
Epoch 91/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0104 - acc: 0.8696 - val_loss: 1.5854 - val_acc: 0.9205
Epoch 92/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0077 - acc: 0.8733 - val_loss: 1.4157 - val_acc: 0.9042
Epoch 93/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0188 - acc: 0.8693 - val_loss: 1.1702 - val_acc: 0.9136
Epoch 94/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0650 - acc: 0.8726 - val_loss: 1.0144 - val_acc: 0.9179
Epoch 95/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0145 - acc: 0.8717 - val_loss: 0.9835 - val_acc: 0.9176
Epoch 96/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0429 - acc: 0.8731 - val_loss: 1.4637 - val_acc: 0.9175
Epoch 97/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9917 - acc: 0.8774 - val_loss: 1.0657 - val_acc: 0.9214
Epoch 98/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9655 - acc: 0.8760 - val_loss: 1.1800 - val_acc: 0.9178
Epoch 99/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0168 - acc: 0.8749 - val_loss: 1.0286 - val_acc: 0.9169
Epoch 100/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9850 - acc: 0.8778 - val_loss: 1.2082 - val_acc: 0.9124
Epoch 101/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9965 - acc: 0.8752 - val_loss: 1.4468 - val_acc: 0.9144
Epoch 102/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9649 - acc: 0.8781 - val_loss: 1.3699 - val_acc: 0.8993
Epoch 103/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9572 - acc: 0.8777 - val_loss: 1.3541 - val_acc: 0.8929
Epoch 104/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9912 - acc: 0.8772 - val_loss: 1.3687 - val_acc: 0.9110
Epoch 105/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9536 - acc: 0.8795 - val_loss: 1.2474 - val_acc: 0.9122
Epoch 106/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9543 - acc: 0.8808 - val_loss: 1.1282 - val_acc: 0.9172
Epoch 107/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9702 - acc: 0.8799 - val_loss: 1.1231 - val_acc: 0.9232
Epoch 108/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9113 - acc: 0.8829 - val_loss: 1.1813 - val_acc: 0.9158
Epoch 109/200
469/469 [==============================] - 8s 16ms/step - loss: 1.0012 - acc: 0.8800 - val_loss: 1.3709 - val_acc: 0.9127
Epoch 110/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9754 - acc: 0.8800 - val_loss: 1.3504 - val_acc: 0.9089
Epoch 111/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9439 - acc: 0.8801 - val_loss: 1.2442 - val_acc: 0.9206
Epoch 112/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9128 - acc: 0.8828 - val_loss: 1.0051 - val_acc: 0.9161
Epoch 113/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9382 - acc: 0.8825 - val_loss: 1.1437 - val_acc: 0.9187
Epoch 114/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9475 - acc: 0.8859 - val_loss: 1.1000 - val_acc: 0.9260
Epoch 115/200
469/469 [==============================] - 8s 17ms/step - loss: 0.9182 - acc: 0.8818 - val_loss: 1.0835 - val_acc: 0.9210
Epoch 116/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9328 - acc: 0.8799 - val_loss: 1.6822 - val_acc: 0.9213
Epoch 117/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8787 - acc: 0.8863 - val_loss: 1.3753 - val_acc: 0.9163
Epoch 118/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8794 - acc: 0.8861 - val_loss: 1.0630 - val_acc: 0.9215
Epoch 119/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9163 - acc: 0.8860 - val_loss: 0.9946 - val_acc: 0.9228
Epoch 120/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9028 - acc: 0.8860 - val_loss: 1.3527 - val_acc: 0.9062
Epoch 121/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8880 - acc: 0.8862 - val_loss: 1.8174 - val_acc: 0.8859
Epoch 122/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8878 - acc: 0.8891 - val_loss: 1.3246 - val_acc: 0.9091
Epoch 123/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8882 - acc: 0.8879 - val_loss: 1.2368 - val_acc: 0.9188
Epoch 124/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9060 - acc: 0.8892 - val_loss: 1.2011 - val_acc: 0.9185
Epoch 125/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8937 - acc: 0.8880 - val_loss: 1.5050 - val_acc: 0.8859
Epoch 126/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8494 - acc: 0.8884 - val_loss: 1.2374 - val_acc: 0.9234
Epoch 127/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8918 - acc: 0.8872 - val_loss: 1.3797 - val_acc: 0.9124
Epoch 128/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8981 - acc: 0.8902 - val_loss: 0.9878 - val_acc: 0.9297
Epoch 129/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8784 - acc: 0.8897 - val_loss: 1.0629 - val_acc: 0.9256
Epoch 130/200
469/469 [==============================] - 8s 16ms/step - loss: 0.9153 - acc: 0.8897 - val_loss: 1.2220 - val_acc: 0.9147
Epoch 131/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8601 - acc: 0.8903 - val_loss: 1.0871 - val_acc: 0.9153
Epoch 132/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8749 - acc: 0.8895 - val_loss: 1.0051 - val_acc: 0.9278
Epoch 133/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8604 - acc: 0.8907 - val_loss: 0.9140 - val_acc: 0.9232
Epoch 134/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8721 - acc: 0.8926 - val_loss: 0.9966 - val_acc: 0.9291
Epoch 135/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8431 - acc: 0.8921 - val_loss: 1.0598 - val_acc: 0.9169
Epoch 136/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8776 - acc: 0.8908 - val_loss: 1.1873 - val_acc: 0.9303
Epoch 137/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8350 - acc: 0.8928 - val_loss: 0.7634 - val_acc: 0.9347
Epoch 138/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8286 - acc: 0.8913 - val_loss: 1.3864 - val_acc: 0.9197
Epoch 139/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8498 - acc: 0.8936 - val_loss: 1.1783 - val_acc: 0.9197
Epoch 140/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8393 - acc: 0.8917 - val_loss: 0.9442 - val_acc: 0.9212
Epoch 141/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8934 - acc: 0.8892 - val_loss: 0.9480 - val_acc: 0.9319
Epoch 142/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8285 - acc: 0.8947 - val_loss: 1.6074 - val_acc: 0.9015
Epoch 143/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8398 - acc: 0.8943 - val_loss: 0.8931 - val_acc: 0.9273
Epoch 144/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8375 - acc: 0.8917 - val_loss: 1.0190 - val_acc: 0.9093
Epoch 145/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8488 - acc: 0.8950 - val_loss: 1.1567 - val_acc: 0.9176
Epoch 146/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8244 - acc: 0.8947 - val_loss: 1.2812 - val_acc: 0.9293
Epoch 147/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8205 - acc: 0.8965 - val_loss: 1.3081 - val_acc: 0.9222
Epoch 148/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8556 - acc: 0.8954 - val_loss: 1.1994 - val_acc: 0.9133
Epoch 149/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7707 - acc: 0.8970 - val_loss: 1.0921 - val_acc: 0.9303
Epoch 150/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8535 - acc: 0.8975 - val_loss: 1.0490 - val_acc: 0.9345
Epoch 151/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8404 - acc: 0.8956 - val_loss: 1.1663 - val_acc: 0.9271
Epoch 152/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8214 - acc: 0.8970 - val_loss: 1.4159 - val_acc: 0.9178
Epoch 153/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8187 - acc: 0.8975 - val_loss: 0.9022 - val_acc: 0.9345
Epoch 154/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8229 - acc: 0.8960 - val_loss: 1.3234 - val_acc: 0.9189
Epoch 155/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8241 - acc: 0.8983 - val_loss: 1.0299 - val_acc: 0.9273
Epoch 156/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8080 - acc: 0.8969 - val_loss: 0.8351 - val_acc: 0.9223
Epoch 157/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7947 - acc: 0.8987 - val_loss: 1.1529 - val_acc: 0.9226
Epoch 158/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7725 - acc: 0.9026 - val_loss: 0.8885 - val_acc: 0.9298
Epoch 159/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8801 - acc: 0.8942 - val_loss: 0.9046 - val_acc: 0.9278
Epoch 160/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7590 - acc: 0.8998 - val_loss: 1.5230 - val_acc: 0.9112
Epoch 161/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8042 - acc: 0.9004 - val_loss: 1.1263 - val_acc: 0.9227
Epoch 162/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7831 - acc: 0.8993 - val_loss: 1.2202 - val_acc: 0.9159
Epoch 163/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8149 - acc: 0.8987 - val_loss: 1.1513 - val_acc: 0.9227
Epoch 164/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8184 - acc: 0.8980 - val_loss: 1.2699 - val_acc: 0.9278
Epoch 165/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8239 - acc: 0.8995 - val_loss: 1.1698 - val_acc: 0.9232
Epoch 166/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7718 - acc: 0.8998 - val_loss: 1.6231 - val_acc: 0.9073
Epoch 167/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7891 - acc: 0.9003 - val_loss: 0.9288 - val_acc: 0.9340
Epoch 168/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7962 - acc: 0.9029 - val_loss: 1.0654 - val_acc: 0.9281
Epoch 169/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8129 - acc: 0.8993 - val_loss: 1.1235 - val_acc: 0.9266
Epoch 170/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8058 - acc: 0.9005 - val_loss: 0.8428 - val_acc: 0.9296
Epoch 171/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8037 - acc: 0.9002 - val_loss: 1.1931 - val_acc: 0.9304
Epoch 172/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7959 - acc: 0.9019 - val_loss: 1.1194 - val_acc: 0.9307
Epoch 173/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7962 - acc: 0.9012 - val_loss: 0.9045 - val_acc: 0.9335
Epoch 174/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7910 - acc: 0.9020 - val_loss: 1.1400 - val_acc: 0.9130
Epoch 175/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7790 - acc: 0.9021 - val_loss: 0.9929 - val_acc: 0.9266
Epoch 176/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7619 - acc: 0.9052 - val_loss: 1.3497 - val_acc: 0.9316
Epoch 177/200
469/469 [==============================] - 8s 16ms/step - loss: 0.8081 - acc: 0.9008 - val_loss: 0.9781 - val_acc: 0.9174
Epoch 178/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7812 - acc: 0.8997 - val_loss: 0.8170 - val_acc: 0.9314
Epoch 179/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7784 - acc: 0.9014 - val_loss: 0.8139 - val_acc: 0.9371
Epoch 180/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7598 - acc: 0.9050 - val_loss: 0.8919 - val_acc: 0.9346
Epoch 181/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7746 - acc: 0.9031 - val_loss: 1.2121 - val_acc: 0.9251
Epoch 182/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7541 - acc: 0.9041 - val_loss: 1.2310 - val_acc: 0.9122
Epoch 183/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7472 - acc: 0.9035 - val_loss: 0.8642 - val_acc: 0.9304
Epoch 184/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7674 - acc: 0.9043 - val_loss: 0.9682 - val_acc: 0.9288
Epoch 185/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7471 - acc: 0.9047 - val_loss: 0.8647 - val_acc: 0.9305
Epoch 186/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7635 - acc: 0.9044 - val_loss: 0.9096 - val_acc: 0.9381
Epoch 187/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7562 - acc: 0.9045 - val_loss: 1.0249 - val_acc: 0.9234
Epoch 188/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7687 - acc: 0.9055 - val_loss: 1.1284 - val_acc: 0.9290
Epoch 189/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7795 - acc: 0.9047 - val_loss: 0.9057 - val_acc: 0.9220
Epoch 190/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7667 - acc: 0.9046 - val_loss: 1.0891 - val_acc: 0.9318
Epoch 191/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7539 - acc: 0.9069 - val_loss: 1.2126 - val_acc: 0.9188
Epoch 192/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7467 - acc: 0.9051 - val_loss: 0.7283 - val_acc: 0.9380
Epoch 193/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7594 - acc: 0.9044 - val_loss: 1.0027 - val_acc: 0.9288
Epoch 194/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7490 - acc: 0.9060 - val_loss: 1.3763 - val_acc: 0.9284
Epoch 195/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7380 - acc: 0.9050 - val_loss: 0.9835 - val_acc: 0.9297
Epoch 196/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7363 - acc: 0.9079 - val_loss: 1.0428 - val_acc: 0.9298
Epoch 197/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7628 - acc: 0.9065 - val_loss: 1.1285 - val_acc: 0.9294
Epoch 198/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7536 - acc: 0.9056 - val_loss: 1.1393 - val_acc: 0.9173
Epoch 199/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7603 - acc: 0.9066 - val_loss: 1.3783 - val_acc: 0.9070
Epoch 200/200
469/469 [==============================] - 8s 16ms/step - loss: 0.7390 - acc: 0.9083 - val_loss: 1.0091 - val_acc: 0.9379
Test score: 1.0091149806976318
Test accuracy: 0.9379000067710876
D:\anaconda3\envs\anyushi\lib\site-packages\numpy\lib\npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  arr = np.asanyarray(arr)
0
[[  5.5 -25.  -14.5 -17.5 -25.5 -16.  -19.  -21.  -20.  -32.5]]
0
[[  0.5 -21.  -15.5 -17.5 -25.5 -10.  -17.  -28.  -15.  -31.5]]
0
[[  3.5 -22.  -16.5 -24.5 -27.5 -14.  -19.  -27.  -16.  -30.5]]
0
[[  5.  -23.5 -11.  -14.  -19.  -14.5 -18.5 -27.5 -20.5 -32. ]]
0
[[  5.5 -26.  -12.5 -19.5 -31.5 -17.  -20.  -23.  -19.  -28.5]]
0
[[  5.  -26.5 -15.  -23.  -32.  -12.5 -20.5 -25.5 -16.5 -29. ]]
0
[[  2.5 -28.  -14.5 -17.5 -24.5 -15.  -16.  -24.  -19.  -34.5]]
0
[[  3.  -24.5 -14.  -18.  -25.  -15.5 -18.5 -24.5 -18.5 -32. ]]
0
[[  3.  -25.5 -19.  -22.  -30.  -14.5 -18.5 -26.5 -15.5 -31. ]]
0
[[  1.  -18.5 -13.  -16.  -27.  -11.5 -15.5 -21.5 -18.5 -31. ]]
0
[[  0.  -25.5 -15.  -20.  -31.  -11.5 -17.5 -27.5 -15.5 -32. ]]
0
[[  3.5 -24.  -13.5 -17.5 -25.5 -16.  -17.  -27.  -19.  -31.5]]
0
[[  4.5 -26.  -14.5 -18.5 -30.5 -17.  -20.  -25.  -18.  -31.5]]
0
[[  1.  -23.5 -13.  -16.  -22.  -14.5 -15.5 -26.5 -20.5 -32. ]]
0
[[  4.  -23.5 -14.  -22.  -30.  -15.5 -21.5 -24.5 -18.5 -30. ]]
0
[[  5.  -25.5 -15.  -18.  -26.  -14.5 -16.5 -21.5 -20.5 -34. ]]
0
[[  4.5 -24.  -15.5 -19.5 -29.5 -17.  -22.  -23.  -19.  -27.5]]
0
[[  7.  -26.5 -12.  -19.  -30.  -17.5 -19.5 -24.5 -18.5 -33. ]]
0
[[  2.  -24.5 -12.  -16.  -24.  -13.5 -13.5 -27.5 -19.5 -30. ]]
0
[[  4.5 -26.  -15.5 -16.5 -27.5 -16.  -19.  -21.  -21.  -32.5]]
1
[[-21.5  24.   -8.5  -2.5 -15.5 -15.  -11.  -20.  -19.  -14.5]]
1
[[-26.   20.5  -9.   -4.  -19.  -11.5 -11.5 -22.5 -19.5 -14. ]]
1
[[-25.   18.5  -6.   -6.  -20.  -13.5  -9.5 -22.5 -18.5 -14. ]]
1
[[-25.   26.5  -5.   -9.  -11.  -13.5 -15.5 -20.5 -19.5 -15. ]]
1
[[-24.5  21.   -7.5  -8.5 -15.5 -16.  -12.  -19.  -21.  -17.5]]
1
[[-23.5  17.   -9.5  -9.5 -15.5 -15.  -15.  -18.  -24.  -13.5]]
1
[[-26.   20.5  -6.   -8.  -18.  -14.5 -12.5 -18.5 -21.5 -13. ]]
1
[[-24.5  16.   -4.5  -4.5 -18.5 -16.  -12.  -20.  -19.  -14.5]]
1
[[-25.5  19.   -8.5  -7.5 -18.5 -12.  -13.  -22.  -22.  -14.5]]
1
[[-24.5  17.   -5.5  -4.5 -19.5 -15.  -11.  -19.  -21.  -13.5]]
1
[[-22.5  21.   -9.5  -9.5 -14.5 -19.  -14.  -20.  -25.  -12.5]]
1
[[-24.5  19.   -7.5  -8.5 -16.5 -17.  -14.  -19.  -22.  -13.5]]
1
[[-25.5  19.   -6.5  -7.5 -17.5 -15.  -13.  -22.  -21.  -14.5]]
1
[[-24.   20.5  -6.   -5.  -18.  -13.5 -12.5 -20.5 -22.5 -14. ]]
1
[[-24.5  21.   -6.5  -9.5 -16.5 -13.  -12.  -24.  -22.  -13.5]]
1
[[-23.5  19.   -9.5 -12.5 -15.5 -14.  -12.  -24.  -20.  -12.5]]
1
[[-23.5  21.   -7.5  -3.5 -17.5 -15.  -11.  -19.  -23.  -14.5]]
1
[[-24.   19.5 -10.  -10.  -18.  -13.5 -10.5 -19.5 -22.5 -16. ]]
1
[[-25.5  20.   -6.5  -6.5 -18.5 -14.  -13.  -20.  -21.  -14.5]]
1
[[-20.5  23.  -11.5  -9.5 -11.5 -15.  -15.  -22.  -24.  -14.5]]
2
[[-12.5 -16.   -2.5 -15.5 -23.5 -19.  -21.    7.  -12.  -16.5]]
2
[[-25.  -12.5  22.  -10.  -19.  -12.5 -10.5 -15.5 -18.5 -23. ]]
2
[[-20.5 -15.   21.5  -7.5 -16.5 -19.  -12.  -14.  -17.  -19.5]]
2
[[-21.   -5.5  20.   -9.  -18.  -15.5 -10.5 -20.5 -17.5 -22. ]]
2
[[-19.5  -9.   21.5 -12.5 -16.5 -15.  -15.  -19.  -11.  -25.5]]
2
[[-21.5  -8.   24.5  -9.5 -17.5 -16.  -14.  -20.  -16.  -21.5]]
2
[[  3.  -22.5  -8.  -17.  -21.  -12.5 -17.5 -27.5 -15.5 -28. ]]
2
[[-22.  -11.5  25.  -10.  -15.  -15.5 -13.5 -15.5 -16.5 -24. ]]
2
[[-21.5 -10.   23.5  -9.5 -16.5 -16.  -13.  -19.  -14.  -24.5]]
2
[[-21.5  -9.   19.5 -12.5 -19.5 -14.  -11.  -23.  -13.  -28.5]]
2
[[-20.5  -8.   26.5 -11.5 -17.5 -14.  -17.  -18.  -19.  -22.5]]
2
[[-20.5 -10.   26.5 -10.5 -16.5 -17.  -11.  -15.  -21.  -21.5]]
2
[[-19.5  -9.   24.5  -8.5 -14.5 -15.  -15.  -18.  -18.  -24.5]]
2
[[-22.   -8.5  26.   -9.  -17.  -12.5  -9.5 -19.5 -14.5 -22. ]]
2
[[-18.   -8.5  16.  -11.  -16.  -18.5 -11.5 -21.5  -4.5 -24. ]]
2
[[-22.5 -11.   23.5 -10.5 -17.5 -17.  -12.  -18.  -13.  -23.5]]
2
[[-19.5 -11.   25.5 -11.5 -17.5 -13.  -15.  -17.  -19.  -22.5]]
2
[[-21.  -11.5  22.  -11.  -14.  -12.5 -11.5 -17.5 -20.5 -25. ]]
2
[[-20.5 -11.   23.5 -13.5 -16.5 -17.  -15.  -17.  -16.  -23.5]]
2
[[-10.  -17.5  -7.   -5.  -25.   -7.5 -17.5 -22.5 -13.5 -21. ]]
3
[[-14.  -11.5 -15.   13.  -20.  -13.5 -23.5 -11.5 -14.5 -16. ]]
3
[[-14.  -13.5 -15.   15.  -22.  -13.5 -23.5 -12.5 -15.5 -14. ]]
3
[[-18.5 -12.  -14.5  16.5 -21.5 -17.  -19.  -15.  -18.  -17.5]]
3
[[-17.  -11.5 -16.    3.  -27.   -9.5 -11.5 -20.5 -14.5 -16. ]]
3
[[-17.5 -14.  -13.5  15.5 -21.5 -16.  -22.  -15.  -16.  -18.5]]
3
[[-18.5  -7.  -13.5   8.5 -18.5 -14.  -19.  -11.  -14.  -14.5]]
3
[[-18.  -13.5 -14.   17.  -22.  -15.5 -22.5 -14.5 -16.5 -19. ]]
3
[[-14.  -11.5 -17.    9.  -22.  -14.5 -19.5 -16.5 -16.5 -17. ]]
3
[[-17.  -10.5 -15.   10.  -23.  -13.5 -16.5 -17.5 -17.5 -17. ]]
3
[[-16.5 -14.  -14.5  10.5 -21.5 -12.  -20.  -14.  -14.  -14.5]]
3
[[-20.  -10.5 -14.   16.  -24.  -14.5 -16.5 -16.5 -18.5 -17. ]]
3
[[-16.   -9.5 -16.   15.  -22.  -16.5 -20.5 -14.5 -17.5 -16. ]]
3
[[-20.5 -10.  -18.5   1.5 -25.5  -5.  -17.  -19.  -13.  -10.5]]
3
[[-20.   -7.5 -14.    5.  -24.  -10.5 -14.5 -19.5 -14.5 -16. ]]
3
[[-21.5  -7.   -2.5   6.5 -24.5 -16.  -11.  -20.  -19.  -20.5]]
3
[[-22.   -6.5  -4.   10.  -19.  -16.5 -14.5 -19.5  -8.5 -12. ]]
3
[[-19.   -7.5 -15.   10.  -23.  -11.5 -13.5 -17.5 -17.5 -17. ]]
3
[[-16.5 -13.   -8.5   0.5 -24.5  -8.  -16.  -16.  -18.  -19.5]]
3
[[-12.  -18.5 -23.    4.  -22.   -7.5 -26.5 -14.5  -9.5 -13. ]]
3
[[-18.5 -16.  -20.5   5.5 -21.5 -11.  -25.  -15.  -10.  -10.5]]
4
[[-15.  -23.5 -20.  -21.   16.  -16.5 -19.5 -16.5 -19.5 -11. ]]
4
[[-15.  -21.5 -18.  -21.   12.  -16.5 -17.5 -23.5 -19.5 -14. ]]
4
[[-14.5 -18.  -12.5 -18.5  11.5  -7.  -21.  -18.  -17.   -5.5]]
4
[[-15.5 -24.  -19.5 -17.5  13.5 -13.  -21.  -20.  -22.  -10.5]]
4
[[-15.5 -21.  -19.5 -20.5  16.5 -14.  -18.  -15.  -19.  -14.5]]
4
[[-13.  -20.5 -18.  -22.   16.  -13.5 -19.5 -22.5 -19.5 -12. ]]
4
[[-10.5 -22.  -17.5 -21.5  15.5 -15.  -17.  -23.  -20.  -14.5]]
4
[[-11.5 -21.  -14.5 -20.5  16.5 -18.  -19.  -20.  -23.  -10.5]]
4
[[-12.5 -23.  -13.5 -22.5  10.5 -12.  -17.  -25.  -17.  -11.5]]
4
[[-14.5 -21.  -16.5 -19.5  17.5 -11.  -24.  -18.  -23.  -14.5]]
4
[[-11.5 -20.  -19.5 -21.5  16.5 -16.  -19.  -22.  -20.  -12.5]]
4
[[-16.  -16.5 -21.  -21.    4.   -9.5 -23.5 -16.5 -15.5  -1. ]]
4
[[-11.  -21.5 -11.  -22.   16.  -12.5 -19.5 -23.5 -16.5 -18. ]]
4
[[-15.5 -23.  -19.5 -18.5  14.5 -15.  -20.  -22.  -19.  -12.5]]
4
[[-16.5 -16.  -16.5 -17.5  15.5 -10.  -26.  -18.  -18.  -11.5]]
4
[[ -9.  -23.5 -16.  -21.   13.  -11.5 -17.5 -26.5 -19.5 -16. ]]
4
[[ -9.  -23.5 -16.  -22.   17.  -15.5 -18.5 -19.5 -21.5 -10. ]]
4
[[-13.5 -25.  -18.5 -21.5  19.5 -16.  -20.  -22.  -18.  -15.5]]
4
[[-15.5  -4.   -8.5 -13.5   6.5 -18.  -16.  -11.  -14.    0.5]]
4
[[-16.  -21.5 -22.  -22.   11.  -11.5 -24.5 -17.5 -20.5  -9. ]]
5
[[-25.5 -14.  -18.5 -11.5 -28.5  15.  -11.  -32.  -10.  -28.5]]
5
[[-26.  -13.5 -19.  -14.  -29.   11.5 -13.5 -25.5 -12.5 -21. ]]
5
[[-18.  -14.5 -16.  -12.  -26.   13.5 -13.5 -23.5  -9.5 -30. ]]
5
[[-23.5  -6.  -16.5  -8.5 -24.5  10.  -11.  -25.   -2.  -28.5]]
5
[[-24.  -13.5 -20.  -15.  -30.   12.5 -16.5 -29.5  -6.5 -27. ]]
5
[[-20.5 -17.  -19.5 -16.5 -28.5  17.  -18.  -25.   -8.  -25.5]]
5
[[-21.5 -16.  -17.5 -13.5 -26.5  13.  -14.  -25.  -10.  -26.5]]
5
[[-13.5 -20.  -19.5 -16.5 -23.5   7.  -12.  -26.  -12.  -27.5]]
5
[[-23.5 -16.  -18.5 -15.5 -24.5  14.  -14.  -25.   -9.  -22.5]]
5
[[-23.  -15.5 -20.  -15.  -25.   15.5 -16.5 -24.5  -9.5 -23. ]]
5
[[-24.  -17.5 -22.  -16.  -25.   17.5 -12.5 -24.5  -8.5 -24. ]]
5
[[-21.  -17.5 -23.  -13.  -27.   12.5 -20.5 -19.5  -7.5 -23. ]]
5
[[-21.  -15.5 -24.  -14.  -25.   13.5 -18.5 -22.5 -10.5 -22. ]]
5
[[-15.  -18.5 -24.  -14.   -7.    7.5 -19.5 -13.5 -14.5 -21. ]]
5
[[-22.  -16.5 -23.  -15.  -25.   13.5 -19.5 -23.5  -7.5 -25. ]]
5
[[-18.5 -17.  -24.5 -15.5 -26.5  11.  -21.  -21.   -8.  -24.5]]
5
[[-25.  -15.5 -16.  -13.  -28.   14.5 -14.5 -26.5 -12.5 -23. ]]
5
[[-24.5 -14.  -20.5 -12.5 -28.5  16.  -14.  -28.  -10.  -24.5]]
5
[[-21.  -18.5 -24.  -12.  -25.   13.5 -20.5 -20.5 -10.5 -25. ]]
5
[[-25.  -14.5 -20.  -13.  -24.   15.5 -14.5 -24.5 -11.5 -26. ]]
6
[[-19.  -13.5  -8.  -20.  -20.  -14.5  14.5 -28.5 -17.5 -30. ]]
6
[[-23.5 -14.   -9.5 -17.5 -16.5 -12.   12.  -29.  -21.  -29.5]]
6
[[-20.  -11.5 -10.  -21.  -20.  -11.5  13.5 -33.5 -19.5 -28. ]]
6
[[-20.  -12.5 -12.  -20.  -19.  -10.5  14.5 -34.5 -14.5 -30. ]]
6
[[-23.  -11.5  -9.  -17.  -19.   -7.5  11.5 -33.5 -18.5 -28. ]]
6
[[-21.5 -15.   -7.5 -18.5 -16.5 -15.   14.  -32.  -19.  -27.5]]
6
[[-20.5 -12.  -12.5 -18.5 -17.5 -13.   16.  -34.  -20.  -26.5]]
6
[[-20.  -11.5 -12.  -19.  -17.  -11.5  17.5 -34.5 -20.5 -25. ]]
6
[[-19.  -11.5 -11.  -19.  -18.  -12.5  18.5 -34.5 -19.5 -26. ]]
6
[[-21.5 -12.  -11.5 -19.5 -22.5 -13.   14.  -34.  -21.  -29.5]]
6
[[-20.5 -12.  -10.5 -20.5 -18.5 -13.   17.  -35.  -21.  -27.5]]
6
[[-21.  -14.5 -12.  -19.  -23.  -12.5  16.5 -36.5 -20.5 -27. ]]
6
[[-19.5 -11.   -9.5 -18.5 -17.5 -14.   16.  -33.  -20.  -27.5]]
6
[[-21.5 -12.  -11.5 -21.5 -19.5 -14.   16.  -33.  -20.  -27.5]]
6
[[-20.5 -12.  -10.5 -20.5 -18.5 -13.   18.  -35.  -19.  -26.5]]
6
[[-21.  -13.5 -12.  -20.  -23.  -10.5  15.5 -34.5 -19.5 -28. ]]
6
[[-21.  -12.5 -10.  -19.  -18.  -14.5  18.5 -33.5 -18.5 -26. ]]
6
[[-23.  -15.5 -12.  -18.  -22.  -12.5  12.5 -34.5 -19.5 -30. ]]
6
[[-20.5 -13.   -8.5 -22.5 -15.5 -13.   14.  -32.  -19.  -28.5]]
6
[[-18.  -10.5 -12.  -18.  -16.  -12.5  14.5 -33.5 -20.5 -29. ]]
7
[[-16.5 -16.  -15.5 -19.5 -14.5 -20.  -30.   17.  -21.  -11.5]]
7
[[-15.5 -21.  -14.5 -17.5 -11.5 -18.  -26.   14.  -22.  -18.5]]
7
[[-14.5  -7.  -15.5 -12.5  -8.5 -21.  -28.    9.  -17.   -8.5]]
7
[[-12.5 -27.  -15.5 -18.5 -12.5 -20.  -24.    9.  -19.  -13.5]]
7
[[-16.  -17.5 -15.  -17.  -11.  -22.5 -26.5  14.5 -21.5 -14. ]]
7
[[-15.  -17.5 -15.  -19.  -10.  -22.5 -26.5  13.5 -19.5 -14. ]]
7
[[-12.5 -22.  -16.5 -17.5 -10.5 -19.  -26.   15.  -21.  -18.5]]
7
[[-13.5 -22.  -15.5 -15.5 -13.5 -18.  -25.   16.  -23.  -19.5]]
7
[[-14.5 -19.  -15.5 -18.5  -9.5 -23.  -27.   14.  -21.  -15.5]]
7
[[-16.  -18.5 -15.  -18.  -11.  -22.5 -27.5  14.5 -20.5 -15. ]]
7
[[-12.5 -24.  -14.5 -19.5 -10.5 -20.  -26.   13.  -22.  -17.5]]
7
[[-14.  -19.5 -16.  -19.   -9.  -22.5 -28.5  15.5 -19.5 -15. ]]
7
[[-14.5 -15.  -14.5 -18.5 -12.5 -20.  -28.   16.  -18.  -12.5]]
7
[[-15.5 -18.  -12.5 -18.5 -10.5 -23.  -26.   15.  -18.  -14.5]]
7
[[-13.5 -20.  -15.5 -17.5 -10.5 -20.  -24.   15.  -22.  -17.5]]
7
[[-15.  -17.5 -15.  -14.   -9.  -19.5 -24.5  13.5 -22.5 -17. ]]
7
[[-15.  -15.5 -16.  -17.  -15.  -19.5 -28.5  15.5 -19.5 -15. ]]
7
[[-12.5 -23.  -14.5 -20.5  -9.5 -21.  -27.   14.  -21.  -16.5]]
7
[[-12.5 -25.  -14.5 -18.5  -8.5 -20.  -27.   13.  -19.  -17.5]]
7
[[-14.  -24.5 -20.  -19.  -15.  -17.5 -27.5  10.5 -25.5 -20. ]]
8
[[-14.5 -13.   -2.5 -16.5 -22.5  -5.  -18.  -20.   15.  -12.5]]
8
[[-17.   -8.5  -5.  -20.  -22.   -3.5 -19.5 -25.5  17.5 -22. ]]
8
[[-16.  -12.5  -5.  -21.  -24.   -8.5 -16.5 -25.5  14.5 -11. ]]
8
[[-14.5 -11.   -2.5 -16.5 -27.5 -10.  -14.  -25.   10.  -13.5]]
8
[[-11.5 -12.    3.5 -20.5 -25.5 -10.  -14.  -26.   12.  -12.5]]
8
[[-17.5 -13.  -13.5 -18.5 -26.5  -6.  -21.  -24.   18.  -14.5]]
8
[[-13.5  -4.   -6.5 -20.5 -19.5 -12.  -14.  -28.   15.  -14.5]]
8
[[-13.5  -9.   -5.5 -16.5 -23.5  -7.  -19.  -26.   15.  -16.5]]
8
[[ -7.5 -18.   -8.5 -16.5 -26.5  -4.  -12.  -28.    9.  -17.5]]
8
[[ -8.5 -14.  -13.5 -14.5 -21.5 -10.  -17.  -27.   16.  -17.5]]
8
[[-20.5 -11.   -7.5 -15.5 -20.5  -3.  -20.  -29.   16.  -22.5]]
8
[[-13.   -9.5  -3.  -23.  -17.   -5.5 -15.5 -26.5  14.5 -20. ]]
8
[[-21.5 -11.   -6.5 -18.5 -20.5  -3.  -22.  -27.   15.  -16.5]]
8
[[-19.5  -5.   -6.5 -17.5 -16.5  -6.  -21.  -27.   15.  -11.5]]
8
[[-18.5  -8.   -5.5 -17.5 -19.5  -5.  -23.  -27.   14.  -14.5]]
8
[[-18.5 -18.  -17.5 -16.5 -20.5   9.  -15.  -24.   -1.  -25.5]]
8
[[-17.5  -4.   -1.5 -18.5 -22.5  -7.  -16.  -29.   11.  -22.5]]
8
[[-18.5  -5.   -2.5 -20.5 -22.5  -3.  -16.  -27.   11.  -16.5]]
8
[[-12.  -17.5 -12.  -15.  -26.   -7.5 -15.5 -26.5  13.5 -13. ]]
8
[[-18.   -9.5  -4.  -15.  -28.   -7.5 -15.5 -30.5  11.5 -18. ]]
9
[[-15.5 -26.  -18.5 -26.5 -10.5 -12.  -20.  -16.  -15.   -0.5]]
9
[[-14.  -22.5 -15.  -22.   12.  -16.5 -17.5 -25.5 -18.5 -12. ]]
9
[[-14.  -26.5 -26.  -22.  -14.  -12.5 -21.5  -7.5 -10.5  -3. ]]
9
[[-13.  -23.5 -24.  -24.  -12.  -13.5 -22.5  -5.5 -12.5   3. ]]
9
[[-10.5 -25.  -30.5 -16.5 -11.5  -7.  -23.  -10.   -9.   -0.5]]
9
[[-17.  -21.5 -19.  -23.   -4.   -9.5 -25.5 -18.5 -13.5   8. ]]
9
[[-12.5 -22.   -5.5 -24.5  -4.5 -12.  -15.  -24.  -19.   -2.5]]
9
[[-19.5 -18.  -17.5 -22.5  -9.5  -9.  -23.  -21.  -13.    9.5]]
9
[[-16.  -24.5 -15.  -27.   -5.  -18.5 -22.5 -18.5 -22.5   8. ]]
9
[[-16.5 -23.  -14.5 -27.5  -6.5 -12.  -25.  -20.  -15.   13.5]]
9
[[-16.  -18.5 -15.  -25.   -8.  -10.5 -23.5 -17.5 -17.5  15. ]]
9
[[-13.5 -26.  -17.5 -23.5  -7.5 -15.  -26.  -20.  -18.    7.5]]
9
[[-19.5 -12.  -16.5 -23.5  -5.5  -9.  -23.  -19.  -10.   10.5]]
9
[[-13.  -23.5 -17.  -24.    0.  -14.5 -20.5 -21.5 -16.5   6. ]]
9
[[-13.5 -21.  -16.5 -23.5  -6.5  -9.  -24.  -20.  -15.    5.5]]
9
[[-16.5 -22.  -21.5 -24.5 -11.5 -14.  -25.  -18.  -14.   11.5]]
9
[[-17.  -22.5 -18.  -22.   -5.  -10.5 -25.5 -16.5 -17.5   6. ]]
9
[[-13.5 -21.  -14.5 -25.5  -8.5 -14.  -25.  -19.  -18.    7.5]]
9
[[-15.5 -21.  -23.5 -26.5  -6.5 -16.  -28.  -11.  -18.    6.5]]
9
[[-18.5 -16.  -16.5 -23.5  -5.5 -10.  -24.  -17.  -13.   10.5]]

Process finished with exit code 0
